{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-21T04:38:00Z", "avg_ns": 9370205, "stddev_ns": 119877, "avg_ts": 1707.760336, "stddev_ts": 21.541214, "samples_ns": [ 9575681, 9373921, 9318251, 9282934, 9300240 ],"samples_ts": [ 1670.9, 1706.86, 1717.06, 1723.59, 1720.39 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-21T04:38:01Z", "avg_ns": 8352988, "stddev_ns": 114633, "avg_ts": 15326.130612, "stddev_ts": 207.224563, "samples_ns": [ 8548351, 8359269, 8280869, 8269282, 8307172 ],"samples_ts": [ 14973.6, 15312.3, 15457.3, 15479, 15408.4 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-21T04:38:02Z", "avg_ns": 14007820, "stddev_ns": 78776, "avg_ts": 36551.929946, "stddev_ts": 204.216963, "samples_ns": [ 14142647, 14000296, 13993168, 13951170, 13951820 ],"samples_ts": [ 36202.6, 36570.7, 36589.3, 36699.4, 36697.7 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-21T04:38:03Z", "avg_ns": 25143665, "stddev_ns": 72526, "avg_ts": 40726.232911, "stddev_ts": 117.018931, "samples_ns": [ 25248411, 25188222, 25110600, 25093734, 25077360 ],"samples_ts": [ 40557, 40653.9, 40779.6, 40807, 40833.6 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-21T04:38:04Z", "avg_ns": 112831934, "stddev_ns": 110240, "avg_ts": 36301.807294, "stddev_ts": 35.430168, "samples_ns": [ 113021000, 112752949, 112782308, 112835892, 112767521 ],"samples_ts": [ 36241.1, 36327.2, 36317.8, 36300.5, 36322.5 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-21T04:38:06Z", "avg_ns": 825026563, "stddev_ns": 847154, "avg_ts": 19858.771268, "stddev_ts": 20.392101, "samples_ns": [ 825853998, 825030114, 823711059, 824859682, 825677964 ],"samples_ts": [ 19838.9, 19858.7, 19890.5, 19862.8, 19843.1 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-21T04:38:12Z", "avg_ns": 57419933, "stddev_ns": 333496, "avg_ts": 278.656335, "stddev_ts": 1.605828, "samples_ns": [ 58011357, 57321547, 57302854, 57250569, 57213341 ],"samples_ts": [ 275.808, 279.127, 279.218, 279.473, 279.655 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-21T04:38:13Z", "avg_ns": 466682695, "stddev_ns": 6611416, "avg_ts": 274.321185, "stddev_ts": 3.961054, "samples_ns": [ 454870455, 469493948, 470194848, 469361851, 469492377 ],"samples_ts": [ 281.399, 272.634, 272.228, 272.711, 272.635 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-21T04:38:17Z", "avg_ns": 1886071505, "stddev_ns": 1256049, "avg_ts": 271.463823, "stddev_ts": 0.180769, "samples_ns": [ 1886945432, 1887217966, 1886779156, 1884766165, 1884648807 ],"samples_ts": [ 271.338, 271.299, 271.362, 271.652, 271.669 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-21T04:38:27Z", "avg_ns": 3967970726, "stddev_ns": 817447, "avg_ts": 258.066429, "stddev_ts": 0.052835, "samples_ns": [ 3967523900, 3967498065, 3967550007, 3967884858, 3969396804 ],"samples_ts": [ 258.095, 258.097, 258.094, 258.072, 257.974 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-21T04:40:14Z", "avg_ns": 6940108, "stddev_ns": 97537, "avg_ts": 2305.797796, "stddev_ts": 31.903851, "samples_ns": [ 7106242, 6949341, 6875289, 6885667, 6884005 ],"samples_ts": [ 2251.54, 2302.38, 2327.17, 2323.67, 2324.23 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-21T04:40:15Z", "avg_ns": 12367207, "stddev_ns": 119409, "avg_ts": 10350.716265, "stddev_ts": 99.106165, "samples_ns": [ 12558675, 12403322, 12314618, 12300860, 12258564 ],"samples_ts": [ 10192.2, 10319.8, 10394.2, 10405.8, 10441.7 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-21T04:40:16Z", "avg_ns": 22947959, "stddev_ns": 102578, "avg_ts": 22311.707062, "stddev_ts": 99.287167, "samples_ns": [ 23117830, 22932551, 22953055, 22858307, 22878053 ],"samples_ts": [ 22147.4, 22326.3, 22306.4, 22398.9, 22379.5 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-21T04:40:18Z", "avg_ns": 41537686, "stddev_ns": 84374, "avg_ts": 24652.393009, "stddev_ts": 49.923925, "samples_ns": [ 41675052, 41534830, 41491489, 41535253, 41451807 ],"samples_ts": [ 24571.1, 24654, 24679.8, 24653.8, 24703.4 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-21T04:40:19Z", "avg_ns": 184509417, "stddev_ns": 1508414, "avg_ts": 22200.608732, "stddev_ts": 183.479004, "samples_ns": [ 185048155, 185234060, 185186084, 185263442, 181815348 ],"samples_ts": [ 22134.8, 22112.6, 22118.3, 22109.1, 22528.4 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-21T04:40:22Z", "avg_ns": 1200399634, "stddev_ns": 113504, "avg_ts": 13648.787977, "stddev_ts": 1.196972, "samples_ns": [ 1200288412, 1200305116, 1200471895, 1200533068, 1200399682 ],"samples_ts": [ 13650.1, 13649.9, 13648, 13647.3, 13648.8 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-21T04:40:30Z", "avg_ns": 58084541, "stddev_ns": 406505, "avg_ts": 275.471258, "stddev_ts": 1.912314, "samples_ns": [ 58785228, 58093002, 57844761, 57881151, 57818566 ],"samples_ts": [ 272.177, 275.42, 276.602, 276.429, 276.728 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-21T04:40:32Z", "avg_ns": 479749164, "stddev_ns": 433704, "avg_ts": 266.806266, "stddev_ts": 0.240482, "samples_ns": [ 480504054, 479649825, 479431477, 479657020, 479503447 ],"samples_ts": [ 266.387, 266.861, 266.983, 266.857, 266.943 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-21T04:40:35Z", "avg_ns": 1942956314, "stddev_ns": 917786, "avg_ts": 263.516008, "stddev_ts": 0.124404, "samples_ns": [ 1944570585, 1942265101, 1942636877, 1942681554, 1942627453 ],"samples_ts": [ 263.297, 263.61, 263.559, 263.553, 263.561 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-21T04:40:46Z", "avg_ns": 4024325211, "stddev_ns": 1852243, "avg_ts": 254.452640, "stddev_ts": 0.117125, "samples_ns": [ 4024840232, 4023625090, 4026736799, 4024740599, 4021683335 ],"samples_ts": [ 254.42, 254.497, 254.3, 254.426, 254.62 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-21T04:42:36Z", "avg_ns": 10897685, "stddev_ns": 68262, "avg_ts": 1468.247293, "stddev_ts": 9.124011, "samples_ns": [ 11013147, 10897360, 10868424, 10873439, 10836058 ],"samples_ts": [ 1452.81, 1468.25, 1472.15, 1471.48, 1476.55 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-21T04:42:38Z", "avg_ns": 36278769, "stddev_ns": 55544, "avg_ts": 3528.240810, "stddev_ts": 5.345625, "samples_ns": [ 36372696, 36268232, 36231870, 36247785, 36273265 ],"samples_ts": [ 3519.12, 3529.26, 3532.8, 3531.25, 3528.77 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-21T04:42:40Z", "avg_ns": 68554190, "stddev_ns": 252940, "avg_ts": 7468.625258, "stddev_ts": 27.481583, "samples_ns": [ 68696258, 68930464, 68342792, 68368469, 68432969 ],"samples_ts": [ 7453.1, 7427.78, 7491.65, 7488.83, 7481.77 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-21T04:42:42Z", "avg_ns": 132167122, "stddev_ns": 118461, "avg_ts": 7747.771404, "stddev_ts": 6.907168, "samples_ns": [ 132080167, 132106307, 132077870, 132221259, 132350009 ],"samples_ts": [ 7752.87, 7751.33, 7753, 7744.59, 7737.06 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-21T04:42:45Z", "avg_ns": 620307954, "stddev_ns": 1910012, "avg_ts": 6603.221687, "stddev_ts": 20.252019, "samples_ns": [ 623663485, 620070931, 619402814, 619240591, 619161953 ],"samples_ts": [ 6567.64, 6605.7, 6612.82, 6614.55, 6615.39 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-21T04:42:50Z", "avg_ns": 3830108528, "stddev_ns": 950116, "avg_ts": 4277.685783, "stddev_ts": 1.057627, "samples_ns": [ 3830047189, 3829032150, 3829605994, 3831572005, 3830285305 ],"samples_ts": [ 4277.75, 4278.89, 4278.25, 4276.05, 4277.49 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-21T04:43:15Z", "avg_ns": 75570881, "stddev_ns": 1355714, "avg_ts": 211.775575, "stddev_ts": 3.750220, "samples_ns": [ 74691816, 74352711, 75050856, 76043126, 77715900 ],"samples_ts": [ 214.214, 215.191, 213.189, 210.407, 205.878 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-21T04:43:17Z", "avg_ns": 698871819, "stddev_ns": 12781091, "avg_ts": 183.202046, "stddev_ts": 3.398462, "samples_ns": [ 678789415, 693332607, 707963990, 707419817, 706853266 ],"samples_ts": [ 188.571, 184.616, 180.8, 180.939, 181.084 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-21T04:43:22Z", "avg_ns": 2787791440, "stddev_ns": 1584213, "avg_ts": 183.657975, "stddev_ts": 0.104216, "samples_ns": [ 2787140770, 2785976404, 2787949156, 2790289052, 2787601822 ],"samples_ts": [ 183.701, 183.778, 183.648, 183.494, 183.67 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-21T04:43:38Z", "avg_ns": 5739220452, "stddev_ns": 1561357, "avg_ts": 178.421454, "stddev_ts": 0.048506, "samples_ns": [ 5740986677, 5738306840, 5740858227, 5737941231, 5738009286 ],"samples_ts": [ 178.367, 178.45, 178.371, 178.461, 178.459 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-21T04:44:13Z", "avg_ns": 21499842, "stddev_ns": 67061, "avg_ts": 744.197253, "stddev_ts": 2.310264, "samples_ns": [ 21605877, 21524045, 21472700, 21444923, 21451667 ],"samples_ts": [ 740.539, 743.355, 745.132, 746.097, 745.863 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-21T04:44:15Z", "avg_ns": 94430703, "stddev_ns": 94773, "avg_ts": 1355.492396, "stddev_ts": 1.346047, "samples_ns": [ 94542810, 94503818, 94420278, 94373916, 94312697 ],"samples_ts": [ 1353.88, 1354.44, 1355.64, 1356.31, 1357.19 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-21T04:44:17Z", "avg_ns": 172146962, "stddev_ns": 870415, "avg_ts": 2974.264056, "stddev_ts": 15.113347, "samples_ns": [ 170670991, 172201743, 172366332, 172550387, 172945359 ],"samples_ts": [ 2999.92, 2973.26, 2970.42, 2967.25, 2960.47 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-21T04:44:20Z", "avg_ns": 318548685, "stddev_ns": 869368, "avg_ts": 3214.598404, "stddev_ts": 8.766387, "samples_ns": [ 317585174, 317911503, 318401633, 319159271, 319685846 ],"samples_ts": [ 3224.33, 3221.02, 3216.06, 3208.43, 3203.14 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-21T04:44:24Z", "avg_ns": 1489555242, "stddev_ns": 1454288, "avg_ts": 2749.816188, "stddev_ts": 2.682772, "samples_ns": [ 1490387474, 1489785735, 1488335129, 1491394777, 1487873099 ],"samples_ts": [ 2748.28, 2749.39, 2752.07, 2746.42, 2752.92 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-21T04:44:35Z", "avg_ns": 10946509769, "stddev_ns": 3596603, "avg_ts": 1496.732909, "stddev_ts": 0.491700, "samples_ns": [ 10946508914, 10947888827, 10941270613, 10945709286, 10951171206 ],"samples_ts": [ 1496.73, 1496.54, 1497.45, 1496.84, 1496.1 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-21T04:45:42Z", "avg_ns": 122680779, "stddev_ns": 77555, "avg_ts": 130.419820, "stddev_ts": 0.082382, "samples_ns": [ 122817824, 122660612, 122632192, 122656091, 122637176 ],"samples_ts": [ 130.274, 130.441, 130.471, 130.446, 130.466 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-21T04:45:44Z", "avg_ns": 1059653253, "stddev_ns": 77723142, "avg_ts": 121.318923, "stddev_ts": 8.946517, "samples_ns": [ 980717673, 980562956, 1065049409, 1136422093, 1135514134 ],"samples_ts": [ 130.517, 130.537, 120.182, 112.634, 112.724 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-21T04:45:51Z", "avg_ns": 4377100236, "stddev_ns": 11716801, "avg_ts": 116.973087, "stddev_ts": 0.312250, "samples_ns": [ 4375530976, 4374287322, 4372118222, 4397113292, 4366451370 ],"samples_ts": [ 117.014, 117.048, 117.106, 116.44, 117.258 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-21T04:46:16Z", "avg_ns": 9007762291, "stddev_ns": 3747693515, "avg_ts": 113.920455, "stddev_ts": 5.912887, "samples_ns": [ 8452604531, 8562972714, 9313474483, 9347283640, 9362476090 ],"samples_ts": [ 121.146, 119.585, 109.948, 109.551, 109.373 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-21T04:47:15Z", "avg_ns": 35126837, "stddev_ns": 123069, "avg_ts": 455.496639, "stddev_ts": 1.588329, "samples_ns": [ 35341382, 35118713, 35046499, 35066614, 35060978 ],"samples_ts": [ 452.727, 455.598, 456.536, 456.274, 456.348 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-21T04:47:19Z", "avg_ns": 212775741, "stddev_ns": 64963, "avg_ts": 601.572376, "stddev_ts": 0.174201, "samples_ns": [ 212748264, 212814933, 212824582, 212811303, 212679627 ],"samples_ts": [ 601.65, 601.462, 601.434, 601.472, 601.844 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-21T04:47:24Z", "avg_ns": 350463021, "stddev_ns": 3426577, "avg_ts": 1461.036155, "stddev_ts": 14.280242, "samples_ns": [ 350713698, 352858009, 354659839, 346774242, 347309318 ],"samples_ts": [ 1459.88, 1451.01, 1443.64, 1476.46, 1474.19 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-21T04:47:29Z", "avg_ns": 647029743, "stddev_ns": 2634878, "avg_ts": 1582.637601, "stddev_ts": 6.453165, "samples_ns": [ 648139728, 648799215, 643575867, 644939159, 649694750 ],"samples_ts": [ 1579.91, 1578.3, 1591.11, 1587.75, 1576.12 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-21T04:47:37Z", "avg_ns": 2800804839, "stddev_ns": 7129275, "avg_ts": 1462.444364, "stddev_ts": 3.726027, "samples_ns": [ 2791739921, 2807390821, 2804927175, 2794532968, 2805433311 ],"samples_ts": [ 1467.19, 1459.01, 1460.29, 1465.72, 1460.02 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-21T04:47:57Z", "avg_ns": 18065495856, "stddev_ns": 6004644, "avg_ts": 906.922322, "stddev_ts": 0.301372, "samples_ns": [ 18063126491, 18067088258, 18059426883, 18075075428, 18062762220 ],"samples_ts": [ 907.041, 906.842, 907.227, 906.442, 907.059 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-21T04:49:49Z", "avg_ns": 214373823, "stddev_ns": 235208, "avg_ts": 74.636050, "stddev_ts": 0.081712, "samples_ns": [ 214778022, 214365749, 214195084, 214234752, 214295509 ],"samples_ts": [ 74.4955, 74.6388, 74.6983, 74.6844, 74.6633 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-21T04:49:53Z", "avg_ns": 1882213895, "stddev_ns": 95256023, "avg_ts": 68.153776, "stddev_ts": 3.674861, "samples_ns": [ 1715765137, 1888533801, 1934996401, 1934863780, 1936910357 ],"samples_ts": [ 74.6023, 67.7774, 66.15, 66.1545, 66.0846 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-21T04:50:05Z", "avg_ns": 6891758825, "stddev_ns": 8037927, "avg_ts": 74.291711, "stddev_ts": 0.086683, "samples_ns": [ 6897837520, 6900294561, 6889447419, 6879795357, 6891419271 ],"samples_ts": [ 74.2262, 74.1997, 74.3166, 74.4208, 74.2953 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-21T04:50:42Z", "avg_ns": 15333736281, "stddev_ns": 293429914, "avg_ts": 66.800561, "stddev_ts": 1.287370, "samples_ns": [ 14943385615, 15108539259, 15438890801, 15591056603, 15586809128 ],"samples_ts": [ 68.5253, 67.7762, 66.326, 65.6787, 65.6966 ]}
