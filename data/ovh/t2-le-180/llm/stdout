{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-19T12:07:02Z", "avg_ns": 9324441, "stddev_ns": 93330, "avg_ts": 1716.055934, "stddev_ts": 16.942993, "samples_ns": [ 9489499, 9291739, 9296204, 9283270, 9261497 ],"samples_ts": [ 1686.07, 1721.96, 1721.13, 1723.53, 1727.58 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-19T12:07:03Z", "avg_ns": 8345935, "stddev_ns": 65906, "avg_ts": 15337.567744, "stddev_ts": 120.430453, "samples_ns": [ 8448940, 8369418, 8319895, 8311096, 8280327 ],"samples_ts": [ 15149.8, 15293.8, 15384.8, 15401.1, 15458.3 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-19T12:07:05Z", "avg_ns": 13836024, "stddev_ns": 153576, "avg_ts": 37008.463586, "stddev_ts": 407.255576, "samples_ns": [ 14078181, 13895197, 13766547, 13734482, 13705716 ],"samples_ts": [ 36368.3, 36847.3, 37191.6, 37278.4, 37356.7 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-19T12:07:06Z", "avg_ns": 24808273, "stddev_ns": 47363, "avg_ts": 41276.670537, "stddev_ts": 78.135484, "samples_ns": [ 24861653, 24751836, 24852098, 24792269, 24783512 ],"samples_ts": [ 41187.9, 41370.7, 41203.8, 41303.2, 41317.8 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-19T12:07:07Z", "avg_ns": 112127362, "stddev_ns": 317854, "avg_ts": 36530.122840, "stddev_ts": 103.515590, "samples_ns": [ 112068747, 111744864, 112478756, 112423874, 111920570 ],"samples_ts": [ 36549, 36654.9, 36415.8, 36433.5, 36597.4 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-19T12:07:09Z", "avg_ns": 787717605, "stddev_ns": 460464, "avg_ts": 20799.337651, "stddev_ts": 12.121877, "samples_ns": [ 787222338, 787469541, 788353180, 787519693, 788023276 ],"samples_ts": [ 20812.4, 20805.9, 20782.6, 20804.6, 20791.3 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-19T12:07:15Z", "avg_ns": 56368876, "stddev_ns": 779285, "avg_ts": 283.887968, "stddev_ts": 3.923077, "samples_ns": [ 56388685, 56959038, 57303515, 55512900, 55680242 ],"samples_ts": [ 283.745, 280.904, 279.215, 288.221, 287.355 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-19T12:07:16Z", "avg_ns": 473393480, "stddev_ns": 18065643, "avg_ts": 270.688357, "stddev_ts": 9.832600, "samples_ns": [ 505636977, 467420529, 464528369, 464488122, 464893407 ],"samples_ts": [ 253.146, 273.843, 275.548, 275.572, 275.332 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-19T12:07:19Z", "avg_ns": 1907173402, "stddev_ns": 3958288, "avg_ts": 268.461045, "stddev_ts": 0.557250, "samples_ns": [ 1908952911, 1908929660, 1911894645, 1903168266, 1902921531 ],"samples_ts": [ 268.21, 268.213, 267.797, 269.025, 269.06 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-19T12:07:29Z", "avg_ns": 3970708449, "stddev_ns": 5119169, "avg_ts": 257.888831, "stddev_ts": 0.332570, "samples_ns": [ 3972789443, 3966306283, 3964352414, 3973810141, 3976283965 ],"samples_ts": [ 257.753, 258.175, 258.302, 257.687, 257.527 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-19T12:09:16Z", "avg_ns": 6936881, "stddev_ns": 41356, "avg_ts": 2306.577091, "stddev_ts": 13.681091, "samples_ns": [ 6999544, 6952816, 6925594, 6914192, 6892261 ],"samples_ts": [ 2285.86, 2301.23, 2310.27, 2314.08, 2321.44 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-19T12:09:18Z", "avg_ns": 12315201, "stddev_ns": 55111, "avg_ts": 10393.824217, "stddev_ts": 46.236509, "samples_ns": [ 12410376, 12307573, 12295051, 12268638, 12294368 ],"samples_ts": [ 10314, 10400.1, 10410.7, 10433.1, 10411.3 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-19T12:09:19Z", "avg_ns": 22768512, "stddev_ns": 85617, "avg_ts": 22487.450814, "stddev_ts": 84.587757, "samples_ns": [ 22876641, 22815774, 22776437, 22718451, 22655257 ],"samples_ts": [ 22380.9, 22440.6, 22479.4, 22536.7, 22599.6 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-19T12:09:20Z", "avg_ns": 41281140, "stddev_ns": 47484, "avg_ts": 24805.541308, "stddev_ts": 27.983602, "samples_ns": [ 41353523, 41301056, 41244087, 41262293, 41244745 ],"samples_ts": [ 24762.1, 24793.6, 24827.8, 24816.8, 24827.4 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-19T12:09:22Z", "avg_ns": 182907607, "stddev_ns": 1094727, "avg_ts": 22394.466587, "stddev_ts": 135.102498, "samples_ns": [ 183399708, 183407831, 183417420, 183363212, 180949867 ],"samples_ts": [ 22333.7, 22332.7, 22331.6, 22338.2, 22636.1 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-19T12:09:24Z", "avg_ns": 1190786341, "stddev_ns": 94610, "avg_ts": 13758.975486, "stddev_ts": 1.056168, "samples_ns": [ 1190712227, 1190842804, 1190697027, 1190765513, 1190914135 ],"samples_ts": [ 13759.8, 13758.3, 13760, 13759.2, 13757.5 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-19T12:09:33Z", "avg_ns": 57316670, "stddev_ns": 278402, "avg_ts": 279.156143, "stddev_ts": 1.349719, "samples_ns": [ 57774052, 57111575, 57163817, 57143773, 57390134 ],"samples_ts": [ 276.941, 280.153, 279.897, 279.996, 278.794 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-19T12:09:34Z", "avg_ns": 487237113, "stddev_ns": 1736624, "avg_ts": 262.708425, "stddev_ts": 0.932030, "samples_ns": [ 490302879, 486638736, 486836211, 486261668, 486146075 ],"samples_ts": [ 261.063, 263.029, 262.922, 263.233, 263.295 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-19T12:09:38Z", "avg_ns": 1971683319, "stddev_ns": 5255086, "avg_ts": 259.678063, "stddev_ts": 0.690935, "samples_ns": [ 1973173245, 1971059455, 1979864021, 1967181596, 1967138280 ],"samples_ts": [ 259.481, 259.759, 258.604, 260.271, 260.277 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-19T12:09:49Z", "avg_ns": 4101922318, "stddev_ns": 8851668, "avg_ts": 249.639980, "stddev_ts": 0.537623, "samples_ns": [ 4094500422, 4116626909, 4096149658, 4099215570, 4103119033 ],"samples_ts": [ 250.092, 248.747, 249.991, 249.804, 249.566 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-19T12:11:39Z", "avg_ns": 10852784, "stddev_ns": 61372, "avg_ts": 1474.313359, "stddev_ts": 8.273336, "samples_ns": [ 10955973, 10837641, 10855033, 10812248, 10803028 ],"samples_ts": [ 1460.39, 1476.34, 1473.97, 1479.8, 1481.07 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-19T12:11:40Z", "avg_ns": 36180445, "stddev_ns": 60478, "avg_ts": 3537.830555, "stddev_ts": 5.895183, "samples_ns": [ 36268626, 36203695, 36180686, 36122837, 36126382 ],"samples_ts": [ 3529.22, 3535.55, 3537.8, 3543.46, 3543.12 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-19T12:11:42Z", "avg_ns": 68422007, "stddev_ns": 87564, "avg_ts": 7482.982288, "stddev_ts": 9.556821, "samples_ns": [ 68456793, 68523280, 68334482, 68326225, 68469256 ],"samples_ts": [ 7479.17, 7471.91, 7492.56, 7493.46, 7477.81 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-19T12:11:44Z", "avg_ns": 131579271, "stddev_ns": 59377, "avg_ts": 7782.382091, "stddev_ts": 3.478184, "samples_ns": [ 131538236, 131668241, 131602051, 131568620, 131519208 ],"samples_ts": [ 7784.81, 7777.12, 7781.03, 7783.01, 7785.93 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-19T12:11:47Z", "avg_ns": 613515729, "stddev_ns": 4399226, "avg_ts": 6676.550430, "stddev_ts": 47.936767, "samples_ns": [ 619170274, 614688955, 614879314, 611500185, 607339917 ],"samples_ts": [ 6615.3, 6663.53, 6661.47, 6698.28, 6744.16 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-19T12:11:52Z", "avg_ns": 3820721809, "stddev_ns": 1358254, "avg_ts": 4288.195390, "stddev_ts": 1.522213, "samples_ns": [ 3820880967, 3820247644, 3821306254, 3822421275, 3818752908 ],"samples_ts": [ 4288.02, 4288.73, 4287.54, 4286.29, 4290.41 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-19T12:12:17Z", "avg_ns": 74629470, "stddev_ns": 78297, "avg_ts": 214.392703, "stddev_ts": 0.223285, "samples_ns": [ 74765050, 74587086, 74573393, 74621206, 74600617 ],"samples_ts": [ 214.004, 214.514, 214.554, 214.416, 214.475 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-19T12:12:19Z", "avg_ns": 676099513, "stddev_ns": 782913, "avg_ts": 189.321446, "stddev_ts": 0.219051, "samples_ns": [ 675522246, 675487352, 675614898, 676705863, 677167207 ],"samples_ts": [ 189.483, 189.493, 189.457, 189.152, 189.023 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-19T12:12:24Z", "avg_ns": 2732090455, "stddev_ns": 12482047, "avg_ts": 187.405398, "stddev_ts": 0.851060, "samples_ns": [ 2728217180, 2725325999, 2726139561, 2726430826, 2754338712 ],"samples_ts": [ 187.668, 187.867, 187.811, 187.791, 185.889 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-19T12:12:39Z", "avg_ns": 5738309648, "stddev_ns": 2838366, "avg_ts": 178.449798, "stddev_ts": 0.088185, "samples_ns": [ 5743245872, 5736283867, 5736924296, 5738117232, 5736976975 ],"samples_ts": [ 178.296, 178.513, 178.493, 178.456, 178.491 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-19T12:13:15Z", "avg_ns": 22198423, "stddev_ns": 63778, "avg_ts": 720.776627, "stddev_ts": 2.058297, "samples_ns": [ 22309238, 22177172, 22191310, 22156437, 22157960 ],"samples_ts": [ 717.192, 721.463, 721.003, 722.138, 722.088 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-19T12:13:17Z", "avg_ns": 97800126, "stddev_ns": 71608, "avg_ts": 1308.792299, "stddev_ts": 0.939138, "samples_ns": [ 97918796, 97808272, 97745881, 97762422, 97765263 ],"samples_ts": [ 1307.21, 1308.68, 1309.52, 1309.3, 1309.26 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-19T12:13:19Z", "avg_ns": 171855998, "stddev_ns": 951958, "avg_ts": 2979.311620, "stddev_ts": 16.508087, "samples_ns": [ 170518931, 171643168, 171806733, 173160935, 172150223 ],"samples_ts": [ 3002.6, 2982.93, 2980.09, 2956.79, 2974.15 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-19T12:13:22Z", "avg_ns": 320468863, "stddev_ns": 4888267, "avg_ts": 3195.905640, "stddev_ts": 48.139721, "samples_ns": [ 328319998, 322232638, 317172385, 317303325, 317315971 ],"samples_ts": [ 3118.91, 3177.83, 3228.53, 3227.2, 3227.07 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-19T12:13:26Z", "avg_ns": 1490927644, "stddev_ns": 2495605, "avg_ts": 2747.289033, "stddev_ts": 4.593121, "samples_ns": [ 1489403592, 1490996347, 1488213668, 1491207387, 1494817230 ],"samples_ts": [ 2750.09, 2747.16, 2752.29, 2746.77, 2740.13 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-19T12:13:37Z", "avg_ns": 10913489543, "stddev_ns": 3829150, "avg_ts": 1501.261494, "stddev_ts": 0.526519, "samples_ns": [ 10909665056, 10912521509, 10914656128, 10911111489, 10919493534 ],"samples_ts": [ 1501.79, 1501.39, 1501.1, 1501.59, 1500.44 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-19T12:14:45Z", "avg_ns": 122503873, "stddev_ns": 66544, "avg_ts": 130.608144, "stddev_ts": 0.068946, "samples_ns": [ 122599832, 122477855, 122516692, 122422127, 122502863 ],"samples_ts": [ 130.506, 130.636, 130.594, 130.695, 130.609 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-19T12:14:47Z", "avg_ns": 1073800170, "stddev_ns": 66657758, "avg_ts": 119.576559, "stddev_ts": 7.527796, "samples_ns": [ 1003233859, 1002938837, 1093803394, 1134436714, 1134588050 ],"samples_ts": [ 127.587, 127.625, 117.023, 112.831, 112.816 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-19T12:14:55Z", "avg_ns": 4478730670, "stddev_ns": 1086873, "avg_ts": 114.318110, "stddev_ts": 0.027712, "samples_ns": [ 4480453767, 4478282980, 4478889525, 4477517081, 4478509998 ],"samples_ts": [ 114.274, 114.33, 114.314, 114.349, 114.324 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-19T12:15:19Z", "avg_ns": 9190503375, "stddev_ns": 221702085, "avg_ts": 111.471783, "stddev_ts": 2.716498, "samples_ns": [ 8906505201, 8993508705, 9346602607, 9352461327, 9353439036 ],"samples_ts": [ 114.972, 113.86, 109.559, 109.49, 109.478 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-19T12:16:16Z", "avg_ns": 35097219, "stddev_ns": 76063, "avg_ts": 455.878285, "stddev_ts": 0.986101, "samples_ns": [ 35222115, 35114501, 35058968, 35059064, 35031447 ],"samples_ts": [ 454.26, 455.652, 456.374, 456.373, 456.732 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-19T12:16:20Z", "avg_ns": 209499077, "stddev_ns": 111003, "avg_ts": 610.981348, "stddev_ts": 0.322230, "samples_ns": [ 209674903, 209524985, 209398633, 209416311, 209480554 ],"samples_ts": [ 610.469, 610.906, 611.274, 611.223, 611.035 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-19T12:16:24Z", "avg_ns": 348967867, "stddev_ns": 1534758, "avg_ts": 1467.206400, "stddev_ts": 6.424276, "samples_ns": [ 351569622, 348326573, 347618561, 348320116, 349004463 ],"samples_ts": [ 1456.33, 1469.88, 1472.88, 1469.91, 1467.03 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-19T12:16:30Z", "avg_ns": 646009907, "stddev_ns": 791179, "avg_ts": 1585.116910, "stddev_ts": 1.941787, "samples_ns": [ 646673409, 646607403, 645602716, 646349080, 644816929 ],"samples_ts": [ 1583.49, 1583.65, 1586.11, 1584.28, 1588.05 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-19T12:16:37Z", "avg_ns": 2796982670, "stddev_ns": 7417417, "avg_ts": 1464.443491, "stddev_ts": 3.887499, "samples_ns": [ 2798610351, 2792822088, 2802482121, 2786404179, 2804594615 ],"samples_ts": [ 1463.58, 1466.62, 1461.56, 1469.99, 1460.46 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-19T12:16:57Z", "avg_ns": 18023798429, "stddev_ns": 3002303, "avg_ts": 909.020395, "stddev_ts": 0.151243, "samples_ns": [ 18024198017, 18028827876, 18022292844, 18022368067, 18021305343 ],"samples_ts": [ 909, 908.767, 909.096, 909.093, 909.146 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-19T12:18:49Z", "avg_ns": 214352518, "stddev_ns": 479234, "avg_ts": 74.643694, "stddev_ts": 0.166405, "samples_ns": [ 214379858, 214141610, 214055012, 214014977, 215171135 ],"samples_ts": [ 74.6339, 74.7169, 74.7471, 74.7611, 74.3594 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-19T12:18:53Z", "avg_ns": 1792009607, "stddev_ns": 47775160, "avg_ts": 71.470106, "stddev_ts": 1.965496, "samples_ns": [ 1709520767, 1790994923, 1819603619, 1819815107, 1820113623 ],"samples_ts": [ 74.8748, 71.4687, 70.345, 70.3368, 70.3253 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-19T12:19:05Z", "avg_ns": 6928634020, "stddev_ns": 100167049, "avg_ts": 73.908362, "stddev_ts": 1.048161, "samples_ns": [ 6884597432, 6883747809, 6883495963, 6883512540, 7107816360 ],"samples_ts": [ 74.3689, 74.3781, 74.3808, 74.3806, 72.0334 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-19T12:19:43Z", "avg_ns": 14748052043, "stddev_ns": 3808814871, "avg_ts": 69.601767, "stddev_ts": 3.797758, "samples_ns": [ 14082283925, 14088518592, 14286556119, 15625358879, 15657542703 ],"samples_ts": [ 72.7155, 72.6833, 71.6758, 65.5345, 65.3998 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-19T12:21:41Z", "avg_ns": 153995456, "stddev_ns": 238367, "avg_ts": 103.899367, "stddev_ts": 0.160279, "samples_ns": [ 153755303, 153895632, 153847457, 154146067, 154332825 ],"samples_ts": [ 104.061, 103.967, 103.999, 103.798, 103.672 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-19T12:21:55Z", "avg_ns": 841647652, "stddev_ns": 10273805, "avg_ts": 152.100483, "stddev_ts": 1.826817, "samples_ns": [ 860016502, 836831542, 836924318, 837623890, 836842008 ],"samples_ts": [ 148.834, 152.958, 152.941, 152.813, 152.956 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-19T12:22:11Z", "avg_ns": 1536049486, "stddev_ns": 3570498, "avg_ts": 333.324033, "stddev_ts": 0.773470, "samples_ns": [ 1537553400, 1541647449, 1533326410, 1534303258, 1533416913 ],"samples_ts": [ 332.997, 332.112, 333.915, 333.702, 333.895 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-19T12:22:33Z", "avg_ns": 2796738831, "stddev_ns": 5016662, "avg_ts": 366.141673, "stddev_ts": 0.656289, "samples_ns": [ 2803034138, 2793423362, 2801330197, 2793338328, 2792568131 ],"samples_ts": [ 365.318, 366.575, 365.541, 366.586, 366.688 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-19T12:23:00Z", "avg_ns": 11509571000, "stddev_ns": 14423045, "avg_ts": 355.878177, "stddev_ts": 0.446324, "samples_ns": [ 11525440996, 11486644451, 11516418671, 11507713158, 11511637724 ],"samples_ts": [ 355.388, 356.588, 355.666, 355.935, 355.814 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-19T12:24:23Z", "avg_ns": 854358789, "stddev_ns": 73496, "avg_ts": 18.727495, "stddev_ts": 0.001332, "samples_ns": [ 854293839, 854314951, 854382499, 854448501, 854354159 ],"samples_ts": [ 18.7289, 18.7285, 18.727, 18.7255, 18.7276 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-19T12:24:38Z", "avg_ns": 6914998156, "stddev_ns": 280864184, "avg_ts": 18.534416, "stddev_ts": 0.736472, "samples_ns": [ 6711813299, 6718845717, 6722045918, 7103567639, 7318718207 ],"samples_ts": [ 19.0709, 19.0509, 19.0418, 18.0191, 17.4894 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz", "gpu_info": "Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB, Tesla V100S-PCIE-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 60, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-19T12:25:26Z", "avg_ns": 29030858870, "stddev_ns": 851660029, "avg_ts": 17.649055, "stddev_ts": 0.538970, "samples_ns": [ 27507394575, 29403775070, 29413842529, 29418826353, 29410455826 ],"samples_ts": [ 18.6132, 17.4127, 17.4068, 17.4038, 17.4088 ]}
