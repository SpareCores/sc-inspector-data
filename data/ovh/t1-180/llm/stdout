{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-21T04:11:17Z", "avg_ns": 9686817, "stddev_ns": 92508, "avg_ts": 1651.848798, "stddev_ts": 15.642962, "samples_ns": [ 9837087, 9713993, 9641236, 9613110, 9628660 ],"samples_ts": [ 1626.5, 1647.11, 1659.54, 1664.39, 1661.71 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-21T04:11:18Z", "avg_ns": 8507363, "stddev_ns": 100601, "avg_ts": 15047.449989, "stddev_ts": 175.737394, "samples_ns": [ 8676541, 8518647, 8466248, 8426128, 8449255 ],"samples_ts": [ 14752.4, 15025.9, 15118.9, 15190.8, 15149.3 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-21T04:11:20Z", "avg_ns": 13952768, "stddev_ns": 132775, "avg_ts": 36697.865003, "stddev_ts": 346.977666, "samples_ns": [ 14159898, 13986063, 13873763, 13931747, 13812373 ],"samples_ts": [ 36158.5, 36607.9, 36904.2, 36750.6, 37068.2 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-21T04:11:21Z", "avg_ns": 24836398, "stddev_ns": 112887, "avg_ts": 41230.486352, "stddev_ts": 186.409210, "samples_ns": [ 25016379, 24868907, 24788402, 24726822, 24781484 ],"samples_ts": [ 40933.2, 41175.9, 41309.6, 41412.5, 41321.2 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-21T04:11:23Z", "avg_ns": 119958743, "stddev_ns": 15822522, "avg_ts": 34559.552682, "stddev_ts": 3932.578806, "samples_ns": [ 111408710, 111190580, 111317945, 118108774, 147767709 ],"samples_ts": [ 36765.5, 36837.7, 36795.5, 34679.9, 27719.2 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-21T04:11:25Z", "avg_ns": 887893848, "stddev_ns": 30263651, "avg_ts": 18469.182408, "stddev_ts": 606.167343, "samples_ns": [ 940418300, 875734440, 875276221, 884333095, 863707188 ],"samples_ts": [ 17422, 18708.9, 18718.7, 18527, 18969.4 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-21T04:11:32Z", "avg_ns": 69321809, "stddev_ns": 2221496, "avg_ts": 230.989732, "stddev_ts": 7.104825, "samples_ns": [ 73275272, 68722206, 68228255, 68188229, 68195086 ],"samples_ts": [ 218.355, 232.821, 234.507, 234.645, 234.621 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-21T04:11:34Z", "avg_ns": 485109899, "stddev_ns": 24945632, "avg_ts": 264.381109, "stddev_ts": 12.722512, "samples_ns": [ 529687637, 475604694, 473104365, 472728559, 474424241 ],"samples_ts": [ 241.652, 269.131, 270.553, 270.768, 269.801 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-21T04:11:38Z", "avg_ns": 2071823769, "stddev_ns": 265721361, "avg_ts": 249.932884, "stddev_ts": 27.365201, "samples_ns": [ 1961532891, 1943765928, 1943908000, 1963038917, 2546873112 ],"samples_ts": [ 261.02, 263.406, 263.387, 260.82, 201.031 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-21T04:11:49Z", "avg_ns": 4452997203, "stddev_ns": 261851564, "avg_ts": 230.576297, "stddev_ts": 13.157931, "samples_ns": [ 4637419381, 4823779471, 4270983316, 4268554696, 4264249153 ],"samples_ts": [ 220.812, 212.282, 239.757, 239.894, 240.136 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-21T04:12:16Z", "avg_ns": 7006002, "stddev_ns": 85336, "avg_ts": 2284.022620, "stddev_ts": 27.388589, "samples_ns": [ 7156232, 6980317, 6981450, 6967329, 6944685 ],"samples_ts": [ 2235.81, 2292.16, 2291.79, 2296.43, 2303.92 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-21T04:12:18Z", "avg_ns": 12229647, "stddev_ns": 78973, "avg_ts": 10466.717392, "stddev_ts": 67.544125, "samples_ns": [ 12326616, 12238058, 12279932, 12132059, 12171572 ],"samples_ts": [ 10384, 10459.2, 10423.5, 10550.6, 10516.3 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-21T04:12:20Z", "avg_ns": 22851892, "stddev_ns": 79109, "avg_ts": 22405.361659, "stddev_ts": 77.500587, "samples_ns": [ 22914873, 22770553, 22788896, 22952457, 22832681 ],"samples_ts": [ 22343.6, 22485.2, 22467.1, 22307, 22424 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-21T04:12:22Z", "avg_ns": 41261200, "stddev_ns": 58388, "avg_ts": 24817.542403, "stddev_ts": 34.685527, "samples_ns": [ 41307342, 41219419, 41252085, 41331907, 41195251 ],"samples_ts": [ 24789.8, 24842.7, 24823, 24775, 24857.2 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-21T04:12:24Z", "avg_ns": 181890021, "stddev_ns": 462630, "avg_ts": 22519.218235, "stddev_ts": 57.047982, "samples_ns": [ 182704747, 181653289, 181572720, 181750356, 181768997 ],"samples_ts": [ 22418.7, 22548.4, 22558.5, 22536.4, 22534.1 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-21T04:12:27Z", "avg_ns": 1234216257, "stddev_ns": 201045, "avg_ts": 13274.821354, "stddev_ts": 2.112164, "samples_ns": [ 1234414193, 1234056967, 1234109866, 1234055059, 1234445203 ],"samples_ts": [ 13272.7, 13276.5, 13276, 13276.6, 13272.4 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-21T04:12:37Z", "avg_ns": 63832834, "stddev_ns": 1079050, "avg_ts": 250.711067, "stddev_ts": 4.168462, "samples_ns": [ 65642041, 64014176, 63307343, 63128275, 63072338 ],"samples_ts": [ 243.746, 249.945, 252.735, 253.452, 253.677 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-21T04:12:39Z", "avg_ns": 498316511, "stddev_ns": 9571214, "avg_ts": 256.938971, "stddev_ts": 4.823482, "samples_ns": [ 497565551, 492771735, 492880770, 493302016, 515062487 ],"samples_ts": [ 257.253, 259.755, 259.698, 259.476, 248.514 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-21T04:12:43Z", "avg_ns": 2000429244, "stddev_ns": 12219903, "avg_ts": 255.952695, "stddev_ts": 1.560660, "samples_ns": [ 2016321587, 2010011569, 1996786472, 1988699957, 1990326637 ],"samples_ts": [ 253.928, 254.725, 256.412, 257.455, 257.244 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-21T04:12:55Z", "avg_ns": 4147623965, "stddev_ns": 14558493, "avg_ts": 246.890766, "stddev_ts": 0.863729, "samples_ns": [ 4171756808, 4150999672, 4137691527, 4139505330, 4138166488 ],"samples_ts": [ 245.46, 246.688, 247.481, 247.373, 247.453 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-21T04:14:46Z", "avg_ns": 10810009, "stddev_ns": 203795, "avg_ts": 1480.522224, "stddev_ts": 27.359262, "samples_ns": [ 11157836, 10820449, 10719626, 10697561, 10654576 ],"samples_ts": [ 1433.97, 1478.68, 1492.59, 1495.67, 1501.7 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-21T04:14:48Z", "avg_ns": 35355984, "stddev_ns": 163946, "avg_ts": 3620.382478, "stddev_ts": 16.692171, "samples_ns": [ 35633700, 35362809, 35304458, 35252253, 35226703 ],"samples_ts": [ 3592.11, 3619.62, 3625.6, 3630.97, 3633.61 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-21T04:14:50Z", "avg_ns": 69571103, "stddev_ns": 1448556, "avg_ts": 7361.866977, "stddev_ts": 149.476705, "samples_ns": [ 69309408, 69078610, 72116290, 68676544, 68674666 ],"samples_ts": [ 7387.16, 7411.85, 7099.64, 7455.24, 7455.44 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-21T04:14:53Z", "avg_ns": 132552060, "stddev_ns": 144386, "avg_ts": 7725.273819, "stddev_ts": 8.381111, "samples_ns": [ 132636895, 132695302, 132590498, 132513375, 132324233 ],"samples_ts": [ 7720.33, 7716.93, 7723.03, 7727.52, 7738.57 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-21T04:14:56Z", "avg_ns": 620146793, "stddev_ns": 2647897, "avg_ts": 6604.984192, "stddev_ts": 28.217302, "samples_ns": [ 623685304, 620361507, 620905861, 619426552, 616354744 ],"samples_ts": [ 6567.41, 6602.6, 6596.81, 6612.57, 6645.52 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-21T04:15:03Z", "avg_ns": 4268363922, "stddev_ns": 797695, "avg_ts": 3838.473185, "stddev_ts": 0.717250, "samples_ns": [ 4267548444, 4268169779, 4268448967, 4269665235, 4267987185 ],"samples_ts": [ 3839.21, 3838.65, 3838.4, 3837.3, 3838.81 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-21T04:15:31Z", "avg_ns": 85559364, "stddev_ns": 684798, "avg_ts": 187.014257, "stddev_ts": 1.498476, "samples_ns": [ 85687090, 84842056, 84850950, 86227154, 86189570 ],"samples_ts": [ 186.726, 188.586, 188.566, 185.556, 185.637 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-21T04:15:33Z", "avg_ns": 699102917, "stddev_ns": 15530410, "avg_ts": 183.163398, "stddev_ts": 4.029795, "samples_ns": [ 719647424, 712032213, 686893400, 688040786, 688900765 ],"samples_ts": [ 177.865, 179.767, 186.346, 186.035, 185.803 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-21T04:15:39Z", "avg_ns": 2790466019, "stddev_ns": 43513913, "avg_ts": 183.517269, "stddev_ts": 2.835495, "samples_ns": [ 2761573760, 2758755219, 2760165814, 2817428757, 2854406549 ],"samples_ts": [ 185.402, 185.591, 185.496, 181.726, 179.372 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-21T04:15:55Z", "avg_ns": 5709199179, "stddev_ns": 11364692, "avg_ts": 179.360224, "stddev_ts": 0.356599, "samples_ns": [ 5701322727, 5725992285, 5716059165, 5702037510, 5700584209 ],"samples_ts": [ 179.607, 178.834, 179.144, 179.585, 179.631 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-21T04:16:32Z", "avg_ns": 23376193, "stddev_ns": 554945, "avg_ts": 684.758522, "stddev_ts": 15.875958, "samples_ns": [ 22963862, 24312135, 23452513, 23079686, 23072770 ],"samples_ts": [ 696.747, 658.108, 682.23, 693.25, 693.458 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-21T04:16:34Z", "avg_ns": 104649501, "stddev_ns": 62554, "avg_ts": 1223.130883, "stddev_ts": 0.731205, "samples_ns": [ 104723781, 104693453, 104622409, 104563214, 104644648 ],"samples_ts": [ 1222.26, 1222.62, 1223.45, 1224.14, 1223.19 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-21T04:16:37Z", "avg_ns": 189869904, "stddev_ns": 220467, "avg_ts": 2696.586114, "stddev_ts": 3.117565, "samples_ns": [ 190255965, 189821642, 189706566, 189785460, 189779890 ],"samples_ts": [ 2691.11, 2697.27, 2698.91, 2697.78, 2697.86 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-21T04:16:41Z", "avg_ns": 348826321, "stddev_ns": 1433785, "avg_ts": 2935.597802, "stddev_ts": 12.017742, "samples_ns": [ 351230899, 348747500, 348695652, 347672261, 347785296 ],"samples_ts": [ 2915.46, 2936.22, 2936.66, 2945.3, 2944.35 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-21T04:16:45Z", "avg_ns": 1624645646, "stddev_ns": 606991, "avg_ts": 2521.165440, "stddev_ts": 0.940057, "samples_ns": [ 1625126197, 1625052663, 1625034173, 1624237279, 1623777920 ],"samples_ts": [ 2520.42, 2520.53, 2520.56, 2521.8, 2522.51 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-21T04:16:58Z", "avg_ns": 12255582848, "stddev_ns": 3759387, "avg_ts": 1336.860224, "stddev_ts": 0.409756, "samples_ns": [ 12260341384, 12254120752, 12256735735, 12250162473, 12256553900 ],"samples_ts": [ 1336.34, 1337.02, 1336.73, 1337.45, 1336.75 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-21T04:18:14Z", "avg_ns": 140806341, "stddev_ns": 1371806, "avg_ts": 113.639979, "stddev_ts": 1.120536, "samples_ns": [ 138397484, 140978197, 141605420, 141631771, 141418834 ],"samples_ts": [ 115.609, 113.493, 112.99, 112.969, 113.139 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-21T04:18:17Z", "avg_ns": 1147027637, "stddev_ns": 1663199, "avg_ts": 111.592965, "stddev_ts": 0.161973, "samples_ns": [ 1144416577, 1147459231, 1146473493, 1148488358, 1148300526 ],"samples_ts": [ 111.847, 111.551, 111.647, 111.451, 111.469 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-21T04:18:26Z", "avg_ns": 4575220273, "stddev_ns": 8238469, "avg_ts": 111.907470, "stddev_ts": 0.201351, "samples_ns": [ 4586855956, 4580473179, 4572544520, 4567698293, 4568529417 ],"samples_ts": [ 111.623, 111.779, 111.973, 112.091, 112.071 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-21T04:18:51Z", "avg_ns": 9482200068, "stddev_ns": 63788353, "avg_ts": 107.995751, "stddev_ts": 0.731319, "samples_ns": [ 9375809638, 9469214292, 9523793685, 9517022544, 9525160184 ],"samples_ts": [ 109.217, 108.14, 107.52, 107.597, 107.505 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-21T04:19:51Z", "avg_ns": 39221165, "stddev_ns": 115089, "avg_ts": 407.945783, "stddev_ts": 1.189383, "samples_ns": [ 39421428, 39209578, 39177421, 39146105, 39151297 ],"samples_ts": [ 405.871, 408.064, 408.399, 408.725, 408.671 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-21T04:19:56Z", "avg_ns": 214188253, "stddev_ns": 70836, "avg_ts": 597.605183, "stddev_ts": 0.191224, "samples_ns": [ 214253603, 214248034, 214205948, 214102188, 214131495 ],"samples_ts": [ 597.423, 597.438, 597.556, 597.845, 597.764 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-21T04:20:01Z", "avg_ns": 365226257, "stddev_ns": 201187, "avg_ts": 1401.871069, "stddev_ts": 0.770149, "samples_ns": [ 365277537, 365056604, 365168019, 365079217, 365549909 ],"samples_ts": [ 1401.67, 1402.52, 1402.09, 1402.44, 1400.63 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-21T04:20:07Z", "avg_ns": 676992810, "stddev_ns": 139134, "avg_ts": 1512.571507, "stddev_ts": 0.310856, "samples_ns": [ 676821198, 677181525, 676898831, 677048321, 677014175 ],"samples_ts": [ 1512.95, 1512.15, 1512.78, 1512.45, 1512.52 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-21T04:20:15Z", "avg_ns": 2984336384, "stddev_ns": 583519, "avg_ts": 1372.499477, "stddev_ts": 0.268324, "samples_ns": [ 2984480307, 2984001278, 2985266074, 2984181550, 2983752711 ],"samples_ts": [ 1372.43, 1372.65, 1372.07, 1372.57, 1372.77 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-21T04:22:34Z", "avg_ns": 241731003, "stddev_ns": 693377, "avg_ts": 66.189709, "stddev_ts": 0.189181, "samples_ns": [ 241680754, 241169768, 241440573, 241435954, 242927969 ],"samples_ts": [ 66.203, 66.3433, 66.2689, 66.2702, 65.8631 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-21T04:22:39Z", "avg_ns": 1964346778, "stddev_ns": 7128025, "avg_ts": 65.162300, "stddev_ts": 0.237607, "samples_ns": [ 1951600439, 1967371570, 1967328311, 1967784148, 1967649423 ],"samples_ts": [ 65.5872, 65.0614, 65.0629, 65.0478, 65.0522 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-21T04:22:53Z", "avg_ns": 7812861792, "stddev_ns": 120783833, "avg_ts": 65.545284, "stddev_ts": 0.996069, "samples_ns": [ 7741707964, 7744371675, 7739883421, 7817508938, 8020836966 ],"samples_ts": [ 66.1353, 66.1125, 66.1509, 65.494, 63.8337 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 36, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-21T04:23:36Z", "avg_ns": 16009788663, "stddev_ns": 306822661, "avg_ts": 63.979794, "stddev_ts": 1.234330, "samples_ns": [ 15659843522, 15690990235, 16185139269, 16256913841, 16256056449 ],"samples_ts": [ 65.3902, 65.2604, 63.2679, 62.9886, 62.9919 ]}
