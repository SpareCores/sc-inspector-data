{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-19T10:43:31Z", "avg_ns": 9544858, "stddev_ns": 109492, "avg_ts": 1676.469345, "stddev_ts": 18.987687, "samples_ns": [ 9732685, 9543290, 9480404, 9460908, 9507005 ],"samples_ts": [ 1643.95, 1676.57, 1687.69, 1691.17, 1682.97 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-19T10:43:32Z", "avg_ns": 8604781, "stddev_ns": 57498, "avg_ts": 14875.978522, "stddev_ts": 98.640137, "samples_ns": [ 8704829, 8561731, 8594816, 8572425, 8590104 ],"samples_ts": [ 14704.5, 14950.2, 14892.7, 14931.6, 14900.9 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-19T10:43:33Z", "avg_ns": 14143142, "stddev_ns": 60881, "avg_ts": 36201.821108, "stddev_ts": 154.807454, "samples_ns": [ 14242759, 14156813, 14108896, 14116558, 14090687 ],"samples_ts": [ 35948.1, 36166.3, 36289.2, 36269.5, 36336.1 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-19T10:43:34Z", "avg_ns": 25348726, "stddev_ns": 87814, "avg_ts": 40396.890719, "stddev_ts": 139.195341, "samples_ns": [ 25485036, 25366091, 25281722, 25347317, 25263468 ],"samples_ts": [ 40180.4, 40368.9, 40503.6, 40398.8, 40532.8 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-19T10:43:36Z", "avg_ns": 148714933, "stddev_ns": 51275740, "avg_ts": 29968.695380, "stddev_ts": 8854.848623, "samples_ns": [ 222428848, 183139597, 112764367, 112553263, 112688592 ],"samples_ts": [ 18414.9, 22365.5, 36323.5, 36391.7, 36348 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-19T10:43:38Z", "avg_ns": 890345083, "stddev_ns": 765359, "avg_ts": 18401.864572, "stddev_ts": 15.792403, "samples_ns": [ 891315352, 889434859, 890087688, 890933822, 889953698 ],"samples_ts": [ 18381.8, 18420.7, 18407.2, 18389.7, 18409.9 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-19T10:43:45Z", "avg_ns": 59733575, "stddev_ns": 315290, "avg_ts": 267.861987, "stddev_ts": 1.404185, "samples_ns": [ 60291991, 59647807, 59533316, 59573641, 59621121 ],"samples_ts": [ 265.375, 268.241, 268.757, 268.575, 268.361 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-19T10:43:46Z", "avg_ns": 481242835, "stddev_ns": 471788, "avg_ts": 265.978189, "stddev_ts": 0.260191, "samples_ns": [ 481962910, 480734037, 480986610, 481412631, 481117990 ],"samples_ts": [ 265.581, 266.259, 266.12, 265.884, 266.047 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-19T10:43:49Z", "avg_ns": 1989354347, "stddev_ns": 1541310, "avg_ts": 257.370059, "stddev_ts": 0.199280, "samples_ns": [ 1991424184, 1987663726, 1990401768, 1988296473, 1988985586 ],"samples_ts": [ 257.102, 257.589, 257.234, 257.507, 257.418 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-19T10:44:00Z", "avg_ns": 4143521269, "stddev_ns": 69144627, "avg_ts": 247.186807, "stddev_ts": 4.045856, "samples_ns": [ 4140863481, 4101120587, 4109402217, 4263795748, 4102424314 ],"samples_ts": [ 247.291, 249.688, 249.185, 240.162, 249.609 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-19T10:45:48Z", "avg_ns": 7068367, "stddev_ns": 112250, "avg_ts": 2264.055147, "stddev_ts": 35.331574, "samples_ns": [ 7261616, 7069997, 7004211, 7017017, 6988994 ],"samples_ts": [ 2203.37, 2263.08, 2284.34, 2280.17, 2289.31 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-19T10:45:50Z", "avg_ns": 12472423, "stddev_ns": 75862, "avg_ts": 10262.940562, "stddev_ts": 61.826559, "samples_ns": [ 12605504, 12441970, 12460906, 12426585, 12427154 ],"samples_ts": [ 10154.3, 10287.8, 10272.1, 10300.5, 10300 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-19T10:45:51Z", "avg_ns": 23131141, "stddev_ns": 63314, "avg_ts": 22134.793978, "stddev_ts": 60.376849, "samples_ns": [ 23221182, 23094768, 23133858, 23152524, 23053375 ],"samples_ts": [ 22048.8, 22169.5, 22132.1, 22114.2, 22209.3 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-19T10:45:53Z", "avg_ns": 41773628, "stddev_ns": 63168, "avg_ts": 24513.116912, "stddev_ts": 36.733904, "samples_ns": [ 41875996, 41774649, 41757061, 41754581, 41705856 ],"samples_ts": [ 24453.1, 24512.5, 24522.8, 24524.3, 24552.9 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-19T10:45:55Z", "avg_ns": 184064633, "stddev_ns": 44573, "avg_ts": 22253.053789, "stddev_ts": 5.261827, "samples_ns": [ 184045337, 184014890, 184062043, 184067583, 184133313 ],"samples_ts": [ 22255.4, 22259.1, 22253.4, 22252.7, 22244.8 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-19T10:45:57Z", "avg_ns": 1241415257, "stddev_ns": 551593, "avg_ts": 13197.842136, "stddev_ts": 5.863209, "samples_ns": [ 1240937281, 1241945014, 1242083772, 1241026879, 1241083339 ],"samples_ts": [ 13202.9, 13192.2, 13190.7, 13202, 13201.4 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-19T10:46:06Z", "avg_ns": 61195978, "stddev_ns": 519559, "avg_ts": 261.470000, "stddev_ts": 2.195121, "samples_ns": [ 62123795, 60972652, 61005845, 60956385, 60921213 ],"samples_ts": [ 257.55, 262.413, 262.27, 262.483, 262.634 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-19T10:46:08Z", "avg_ns": 499346728, "stddev_ns": 483781, "avg_ts": 256.335105, "stddev_ts": 0.248279, "samples_ns": [ 499812301, 498770135, 499540102, 498890114, 499720989 ],"samples_ts": [ 256.096, 256.631, 256.236, 256.57, 256.143 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-19T10:46:12Z", "avg_ns": 2031049918, "stddev_ns": 11928280, "avg_ts": 252.093277, "stddev_ts": 1.470220, "samples_ns": [ 2051871018, 2030328082, 2023870216, 2024798132, 2024382143 ],"samples_ts": [ 249.528, 252.176, 252.981, 252.865, 252.917 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-19T10:46:23Z", "avg_ns": 4272437649, "stddev_ns": 151562197, "avg_ts": 239.907800, "stddev_ts": 8.175186, "samples_ns": [ 4186967029, 4177879600, 4192671982, 4269051623, 4535618013 ],"samples_ts": [ 244.568, 245.1, 244.236, 239.866, 225.769 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-19T10:48:14Z", "avg_ns": 10928497, "stddev_ns": 98926, "avg_ts": 1464.156928, "stddev_ts": 13.094869, "samples_ns": [ 11102846, 10897784, 10866881, 10870467, 10904510 ],"samples_ts": [ 1441.07, 1468.19, 1472.36, 1471.88, 1467.28 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-19T10:48:16Z", "avg_ns": 35482807, "stddev_ns": 81075, "avg_ts": 3607.395803, "stddev_ts": 8.201132, "samples_ns": [ 35620369, 35478642, 35436959, 35464290, 35413777 ],"samples_ts": [ 3593.45, 3607.8, 3612.05, 3609.26, 3614.41 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-19T10:48:18Z", "avg_ns": 69126689, "stddev_ns": 88250, "avg_ts": 7406.700097, "stddev_ts": 9.390975, "samples_ns": [ 69145626, 69163477, 69244559, 69045613, 69034173 ],"samples_ts": [ 7404.66, 7402.75, 7394.08, 7415.39, 7416.62 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-19T10:48:21Z", "avg_ns": 132949421, "stddev_ns": 91812, "avg_ts": 7702.180076, "stddev_ts": 5.277585, "samples_ns": [ 133032617, 132974537, 132857176, 133033572, 132849205 ],"samples_ts": [ 7697.36, 7700.72, 7707.52, 7697.31, 7707.99 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-19T10:48:23Z", "avg_ns": 625078645, "stddev_ns": 8745619, "avg_ts": 6553.816883, "stddev_ts": 93.046158, "samples_ns": [ 630587896, 630472013, 630248990, 623772669, 610311658 ],"samples_ts": [ 6495.53, 6496.72, 6499.02, 6566.49, 6711.33 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-19T10:48:29Z", "avg_ns": 4274053311, "stddev_ns": 1808634, "avg_ts": 3833.364057, "stddev_ts": 1.620802, "samples_ns": [ 4270934038, 4274113221, 4275262904, 4274710768, 4275245628 ],"samples_ts": [ 3836.16, 3833.31, 3832.28, 3832.77, 3832.29 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-19T10:48:57Z", "avg_ns": 83756102, "stddev_ns": 956530, "avg_ts": 191.050537, "stddev_ts": 2.154105, "samples_ns": [ 83606609, 83551493, 85411785, 83045812, 83164812 ],"samples_ts": [ 191.372, 191.499, 187.328, 192.665, 192.389 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-19T10:48:59Z", "avg_ns": 695754496, "stddev_ns": 1098501, "avg_ts": 183.973306, "stddev_ts": 0.290158, "samples_ns": [ 695191814, 694941499, 694822083, 697304411, 696512675 ],"samples_ts": [ 184.122, 184.188, 184.22, 183.564, 183.773 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-19T10:49:04Z", "avg_ns": 2827218503, "stddev_ns": 30082110, "avg_ts": 181.113134, "stddev_ts": 1.928202, "samples_ns": [ 2791762014, 2802912595, 2853978238, 2827733553, 2859706115 ],"samples_ts": [ 183.397, 182.667, 179.399, 181.064, 179.039 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-19T10:49:20Z", "avg_ns": 5709837675, "stddev_ns": 1950845, "avg_ts": 179.339616, "stddev_ts": 0.061259, "samples_ns": [ 5711496237, 5707432771, 5710920535, 5708018935, 5711319898 ],"samples_ts": [ 179.288, 179.415, 179.306, 179.397, 179.293 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-19T10:49:56Z", "avg_ns": 22636910, "stddev_ns": 127441, "avg_ts": 706.828059, "stddev_ts": 3.957074, "samples_ns": [ 22847704, 22666419, 22561910, 22541465, 22567053 ],"samples_ts": [ 700.289, 705.89, 709.16, 709.803, 708.998 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-19T10:49:58Z", "avg_ns": 102429212, "stddev_ns": 100930, "avg_ts": 1249.644451, "stddev_ts": 1.218753, "samples_ns": [ 102547579, 102415302, 102515727, 102332114, 102335342 ],"samples_ts": [ 1248.2, 1249.81, 1248.59, 1250.83, 1250.79 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-19T10:50:01Z", "avg_ns": 185711729, "stddev_ns": 1225729, "avg_ts": 2757.057963, "stddev_ts": 18.357654, "samples_ns": [ 183524342, 186405567, 186206595, 186211908, 186210233 ],"samples_ts": [ 2789.82, 2746.7, 2749.63, 2749.56, 2749.58 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-19T10:50:04Z", "avg_ns": 352510391, "stddev_ns": 139911, "avg_ts": 2904.879260, "stddev_ts": 1.137516, "samples_ns": [ 352474504, 352634687, 352631023, 352513221, 352298523 ],"samples_ts": [ 2905.17, 2903.86, 2903.89, 2904.86, 2906.63 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-19T10:50:08Z", "avg_ns": 1626631032, "stddev_ns": 730377, "avg_ts": 2518.088355, "stddev_ts": 1.129889, "samples_ns": [ 1627382446, 1627275226, 1626673914, 1626151038, 1625672537 ],"samples_ts": [ 2516.93, 2517.09, 2518.02, 2518.83, 2519.57 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-12-19T10:50:20Z", "avg_ns": 12270656536, "stddev_ns": 2025779, "avg_ts": 1335.217908, "stddev_ts": 0.220082, "samples_ns": [ 12269349124, 12270569840, 12271039422, 12268517217, 12273807079 ],"samples_ts": [ 1335.36, 1335.23, 1335.18, 1335.45, 1334.88 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-19T10:51:36Z", "avg_ns": 137967025, "stddev_ns": 352927, "avg_ts": 115.970345, "stddev_ts": 0.295831, "samples_ns": [ 138574037, 137908479, 137916006, 137716031, 137720572 ],"samples_ts": [ 115.462, 116.019, 116.013, 116.181, 116.177 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-19T10:51:38Z", "avg_ns": 1140749199, "stddev_ns": 19141044, "avg_ts": 112.232353, "stddev_ts": 1.891701, "samples_ns": [ 1122155261, 1118457152, 1147788255, 1157177389, 1158167939 ],"samples_ts": [ 114.066, 114.443, 111.519, 110.614, 110.519 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-19T10:51:45Z", "avg_ns": 4475619272, "stddev_ns": 6293152, "avg_ts": 114.397758, "stddev_ts": 0.160853, "samples_ns": [ 4467490299, 4482598226, 4473683350, 4481351627, 4472972860 ],"samples_ts": [ 114.606, 114.219, 114.447, 114.251, 114.465 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-19T10:52:10Z", "avg_ns": 9378582162, "stddev_ns": 200399315, "avg_ts": 109.225266, "stddev_ts": 2.358666, "samples_ns": [ 9103514060, 9224778821, 9519218048, 9521424107, 9523975776 ],"samples_ts": [ 112.484, 111.005, 107.572, 107.547, 107.518 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-19T10:53:08Z", "avg_ns": 39254397, "stddev_ns": 116833, "avg_ts": 407.600505, "stddev_ts": 1.205800, "samples_ns": [ 39454195, 39238714, 39169231, 39236330, 39173519 ],"samples_ts": [ 405.534, 407.761, 408.484, 407.785, 408.439 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-19T10:53:12Z", "avg_ns": 214553802, "stddev_ns": 213078, "avg_ts": 596.587429, "stddev_ts": 0.593074, "samples_ns": [ 214704892, 214715297, 214194259, 214543167, 214611395 ],"samples_ts": [ 596.167, 596.138, 597.588, 596.617, 596.427 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-19T10:53:16Z", "avg_ns": 365991402, "stddev_ns": 193131, "avg_ts": 1398.940277, "stddev_ts": 0.736410, "samples_ns": [ 366100856, 365925636, 365731112, 366242799, 365956608 ],"samples_ts": [ 1398.52, 1399.19, 1399.94, 1397.98, 1399.07 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-19T10:53:21Z", "avg_ns": 677672789, "stddev_ns": 131758, "avg_ts": 1511.053778, "stddev_ts": 0.285043, "samples_ns": [ 677837298, 677543051, 677581010, 677625693, 677776896 ],"samples_ts": [ 1510.69, 1511.34, 1511.26, 1511.16, 1510.82 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-19T10:53:28Z", "avg_ns": 2990373378, "stddev_ns": 1448501, "avg_ts": 1369.728876, "stddev_ts": 0.662956, "samples_ns": [ 2988483547, 2990494597, 2992447348, 2989748185, 2990693215 ],"samples_ts": [ 1370.59, 1369.67, 1368.78, 1370.02, 1369.58 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-19T10:55:47Z", "avg_ns": 242263114, "stddev_ns": 1096648, "avg_ts": 66.044973, "stddev_ts": 0.297381, "samples_ns": [ 242197850, 241781484, 241560531, 241603309, 244172396 ],"samples_ts": [ 66.0617, 66.1755, 66.236, 66.2243, 65.5275 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-19T10:55:52Z", "avg_ns": 1965974473, "stddev_ns": 16602688, "avg_ts": 65.111415, "stddev_ts": 0.555565, "samples_ns": [ 1936834707, 1972545127, 1969667571, 1972371849, 1978453115 ],"samples_ts": [ 66.0872, 64.8908, 64.9856, 64.8965, 64.697 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-19T10:56:05Z", "avg_ns": 7823418497, "stddev_ns": 109615449, "avg_ts": 65.454665, "stddev_ts": 0.903633, "samples_ns": [ 7757425665, 7756613143, 7757914983, 7835128928, 8010009768 ],"samples_ts": [ 66.0013, 66.0082, 65.9971, 65.3467, 63.92 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-12-19T10:56:48Z", "avg_ns": 16070533529, "stddev_ns": 257042997, "avg_ts": 63.732213, "stddev_ts": 1.024509, "samples_ns": [ 15800111994, 15783905385, 16195329992, 16285042278, 16288277999 ],"samples_ts": [ 64.8097, 64.8762, 63.2281, 62.8798, 62.8673 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-12-19T10:58:57Z", "avg_ns": 176449333, "stddev_ns": 1755337, "avg_ts": 90.684862, "stddev_ts": 0.914067, "samples_ns": [ 173321589, 177494291, 177119080, 177188657, 177123051 ],"samples_ts": [ 92.3139, 90.1437, 90.3347, 90.2992, 90.3327 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-12-19T10:59:10Z", "avg_ns": 870785590, "stddev_ns": 506237, "avg_ts": 146.993744, "stddev_ts": 0.085341, "samples_ns": [ 871614639, 870584986, 870314704, 870531232, 870882390 ],"samples_ts": [ 146.854, 147.028, 147.073, 147.037, 146.977 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-12-19T10:59:29Z", "avg_ns": 1553929672, "stddev_ns": 1237826, "avg_ts": 329.487408, "stddev_ts": 0.262149, "samples_ns": [ 1552995495, 1552930614, 1555961227, 1553635779, 1554125247 ],"samples_ts": [ 329.685, 329.699, 329.057, 329.55, 329.446 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-12-19T10:59:51Z", "avg_ns": 2841590688, "stddev_ns": 1580885, "avg_ts": 360.361630, "stddev_ts": 0.200265, "samples_ns": [ 2843777689, 2840706564, 2840015659, 2842700764, 2840752767 ],"samples_ts": [ 360.084, 360.474, 360.561, 360.221, 360.468 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-12-19T11:00:22Z", "avg_ns": 11937711201, "stddev_ns": 2186513, "avg_ts": 343.114358, "stddev_ts": 0.062834, "samples_ns": [ 11937636326, 11937484223, 11936064040, 11941373995, 11935997421 ],"samples_ts": [ 343.117, 343.121, 343.162, 343.009, 343.164 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-12-19T11:01:46Z", "avg_ns": 946633438, "stddev_ns": 1682187, "avg_ts": 16.902044, "stddev_ts": 0.029967, "samples_ns": [ 946303180, 945535296, 945522966, 946237919, 949567831 ],"samples_ts": [ 16.9079, 16.9216, 16.9219, 16.9091, 16.8498 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-12-19T11:01:59Z", "avg_ns": 7631536014, "stddev_ns": 83983134, "avg_ts": 16.774127, "stddev_ts": 0.183835, "samples_ns": [ 7577698140, 7565578412, 7568233774, 7713231708, 7732938037 ],"samples_ts": [ 16.8917, 16.9187, 16.9128, 16.5949, 16.5526 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Silver 4214 CPU @ 2.20GHz", "gpu_info": "Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB, Tesla V100-PCIE-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-12-19T11:02:51Z", "avg_ns": 31032092931, "stddev_ns": 173441839, "avg_ts": 16.499464, "stddev_ts": 0.092908, "samples_ns": [ 30722386671, 31101475168, 31104736304, 31104510361, 31127356151 ],"samples_ts": [ 16.6654, 16.4622, 16.4605, 16.4606, 16.4486 ]}
