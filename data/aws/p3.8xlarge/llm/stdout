{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-04-15T10:38:19Z", "avg_ns": 9093007, "stddev_ns": 107301, "avg_ts": 1759.786585, "stddev_ts": 20.431034, "samples_ns": [ 9284810, 9046705, 9046444, 9045242, 9041837 ],"samples_ts": [ 1723.24, 1768.6, 1768.65, 1768.89, 1769.55 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-04-15T10:38:20Z", "avg_ns": 8130066, "stddev_ns": 121181, "avg_ts": 15746.771496, "stddev_ts": 230.067670, "samples_ns": [ 8346599, 8083149, 8070756, 8071843, 8077985 ],"samples_ts": [ 15335.6, 15835.4, 15859.7, 15857.6, 15845.5 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-04-15T10:38:22Z", "avg_ns": 13508463, "stddev_ns": 116441, "avg_ts": 37904.393258, "stddev_ts": 323.222667, "samples_ns": [ 13713248, 13478436, 13478034, 13432602, 13439996 ],"samples_ts": [ 37336.2, 37986.6, 37987.7, 38116.2, 38095.2 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-04-15T10:38:24Z", "avg_ns": 24056369, "stddev_ns": 33449, "avg_ts": 42566.751452, "stddev_ts": 57.839414, "samples_ns": [ 24108901, 24045560, 24065389, 24026645, 24035354 ],"samples_ts": [ 42473.9, 42585.8, 42550.7, 42619.4, 42603.9 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-04-15T10:38:26Z", "avg_ns": 107457994, "stddev_ns": 97450, "avg_ts": 38117.244895, "stddev_ts": 34.485219, "samples_ns": [ 107316738, 107495081, 107550497, 107401305, 107526350 ],"samples_ts": [ 38167.4, 38104.1, 38084.4, 38137.3, 38093 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-04-15T10:38:28Z", "avg_ns": 873352620, "stddev_ns": 243291, "avg_ts": 18759.892203, "stddev_ts": 5.207141, "samples_ns": [ 873571801, 873070194, 873520001, 873108495, 873492610 ],"samples_ts": [ 18755.2, 18766, 18756.3, 18765.1, 18756.9 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-04-15T10:38:35Z", "avg_ns": 57572288, "stddev_ns": 586273, "avg_ts": 277.934234, "stddev_ts": 2.793248, "samples_ns": [ 58612806, 57407878, 57243025, 57240210, 57357524 ],"samples_ts": [ 272.978, 278.707, 279.51, 279.524, 278.952 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-04-15T10:38:37Z", "avg_ns": 476904704, "stddev_ns": 529053, "avg_ts": 268.397699, "stddev_ts": 0.296842, "samples_ns": [ 477831256, 476708069, 476713839, 476771003, 476499357 ],"samples_ts": [ 267.877, 268.508, 268.505, 268.473, 268.626 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-04-15T10:38:40Z", "avg_ns": 1923651982, "stddev_ns": 648246, "avg_ts": 266.160434, "stddev_ts": 0.089472, "samples_ns": [ 1923726882, 1922976118, 1923173753, 1923744498, 1924638661 ],"samples_ts": [ 266.15, 266.254, 266.227, 266.148, 266.024 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-04-15T10:38:52Z", "avg_ns": 4032616521, "stddev_ns": 2775991, "avg_ts": 253.929523, "stddev_ts": 0.174815, "samples_ns": [ 4033048943, 4034379566, 4035399540, 4032046544, 4028208015 ],"samples_ts": [ 253.902, 253.818, 253.754, 253.965, 254.207 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-04-15T10:40:40Z", "avg_ns": 6780759, "stddev_ns": 95406, "avg_ts": 2359.984614, "stddev_ts": 32.608107, "samples_ns": [ 6949774, 6747660, 6741774, 6748155, 6716434 ],"samples_ts": [ 2302.23, 2371.19, 2373.26, 2371.02, 2382.22 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-04-15T10:40:42Z", "avg_ns": 12022632, "stddev_ns": 179416, "avg_ts": 10648.447213, "stddev_ts": 155.798497, "samples_ns": [ 12343407, 11940610, 11948497, 11933576, 11947070 ],"samples_ts": [ 10369.9, 10719.7, 10712.6, 10726, 10713.9 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-04-15T10:40:44Z", "avg_ns": 22180325, "stddev_ns": 144204, "avg_ts": 23084.292624, "stddev_ts": 148.656564, "samples_ns": [ 22436785, 22113216, 22102524, 22139600, 22109504 ],"samples_ts": [ 22819.7, 23153.6, 23164.8, 23126, 23157.5 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-04-15T10:40:46Z", "avg_ns": 40032304, "stddev_ns": 54809, "avg_ts": 25579.379277, "stddev_ts": 34.618536, "samples_ns": [ 40125515, 40032613, 40004305, 39990665, 40008425 ],"samples_ts": [ 25519.9, 25579.1, 25597.2, 25606, 25594.6 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-04-15T10:40:48Z", "avg_ns": 177134166, "stddev_ns": 46979, "avg_ts": 23123.716463, "stddev_ts": 6.133737, "samples_ns": [ 177063654, 177145724, 177114098, 177183625, 177163729 ],"samples_ts": [ 23132.9, 23122.2, 23126.3, 23117.3, 23119.9 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-04-15T10:40:52Z", "avg_ns": 1172813038, "stddev_ns": 51922, "avg_ts": 13969.831070, "stddev_ts": 0.547085, "samples_ns": [ 1172879104, 1172817027, 1172753050, 1172822294, 1172793716 ],"samples_ts": [ 13969, 13969.8, 13970.5, 13969.7, 13970.1 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-04-15T10:41:01Z", "avg_ns": 59693067, "stddev_ns": 454599, "avg_ts": 268.050140, "stddev_ts": 2.021255, "samples_ns": [ 60500894, 59553060, 59460446, 59422900, 59528036 ],"samples_ts": [ 264.459, 268.668, 269.086, 269.256, 268.781 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-04-15T10:41:03Z", "avg_ns": 487856879, "stddev_ns": 490321, "avg_ts": 262.372242, "stddev_ts": 0.263352, "samples_ns": [ 488729416, 487588122, 487597116, 487711891, 487657850 ],"samples_ts": [ 261.904, 262.517, 262.512, 262.45, 262.479 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-04-15T10:41:07Z", "avg_ns": 1978793574, "stddev_ns": 657017, "avg_ts": 258.743535, "stddev_ts": 0.085614, "samples_ns": [ 1979635610, 1979128379, 1978923517, 1978033008, 1978247359 ],"samples_ts": [ 258.633, 258.7, 258.727, 258.843, 258.815 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-04-15T10:41:19Z", "avg_ns": 4100921615, "stddev_ns": 464275, "avg_ts": 249.699971, "stddev_ts": 0.028001, "samples_ns": [ 4101263342, 4100770201, 4100964737, 4101386703, 4100223094 ],"samples_ts": [ 249.679, 249.709, 249.697, 249.672, 249.743 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-04-15T10:43:10Z", "avg_ns": 10457297, "stddev_ns": 99586, "avg_ts": 1530.141533, "stddev_ts": 14.395971, "samples_ns": [ 10630643, 10441610, 10392095, 10430639, 10391502 ],"samples_ts": [ 1505.08, 1532.33, 1539.63, 1533.94, 1539.72 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-04-15T10:43:12Z", "avg_ns": 34213697, "stddev_ns": 52484, "avg_ts": 3741.198700, "stddev_ts": 5.721452, "samples_ns": [ 34260163, 34194865, 34194639, 34146021, 34272798 ],"samples_ts": [ 3736.12, 3743.25, 3743.28, 3748.61, 3734.74 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-04-15T10:43:15Z", "avg_ns": 66612739, "stddev_ns": 206723, "avg_ts": 7686.276501, "stddev_ts": 23.766243, "samples_ns": [ 66973287, 66491585, 66585577, 66545389, 66467857 ],"samples_ts": [ 7644.84, 7700.22, 7689.35, 7694, 7702.97 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-04-15T10:43:18Z", "avg_ns": 128324679, "stddev_ns": 143766, "avg_ts": 7979.766768, "stddev_ts": 8.883769, "samples_ns": [ 128155054, 128377605, 128513925, 128212152, 128364663 ],"samples_ts": [ 7990.32, 7976.47, 7968.01, 7986.76, 7977.27 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-04-15T10:43:21Z", "avg_ns": 592683499, "stddev_ns": 6824720, "avg_ts": 6911.669302, "stddev_ts": 79.190802, "samples_ns": [ 602862500, 595116407, 592184115, 587886228, 585368245 ],"samples_ts": [ 6794.25, 6882.69, 6916.77, 6967.33, 6997.3 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-04-15T10:43:27Z", "avg_ns": 4031453392, "stddev_ns": 1052171, "avg_ts": 4064.043236, "stddev_ts": 1.059519, "samples_ns": [ 4033081398, 4030549650, 4031927758, 4030784562, 4030923593 ],"samples_ts": [ 4062.4, 4064.95, 4063.56, 4064.72, 4064.58 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-04-15T10:43:54Z", "avg_ns": 80357321, "stddev_ns": 693711, "avg_ts": 199.122416, "stddev_ts": 1.701460, "samples_ns": [ 80335682, 79976775, 79965851, 79944576, 81563725 ],"samples_ts": [ 199.164, 200.058, 200.085, 200.139, 196.166 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-04-15T10:43:57Z", "avg_ns": 657292862, "stddev_ns": 381083, "avg_ts": 194.738208, "stddev_ts": 0.112588, "samples_ns": [ 657933020, 657162020, 657232449, 657221614, 656915209 ],"samples_ts": [ 194.549, 194.777, 194.756, 194.759, 194.85 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-04-15T10:44:02Z", "avg_ns": 2656836328, "stddev_ns": 54056984, "avg_ts": 192.772550, "stddev_ts": 3.818060, "samples_ns": [ 2633948318, 2632816827, 2631809155, 2632082350, 2753524993 ],"samples_ts": [ 194.385, 194.469, 194.543, 194.523, 185.943 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-04-15T10:44:18Z", "avg_ns": 5599162440, "stddev_ns": 1243836, "avg_ts": 182.884503, "stddev_ts": 0.040586, "samples_ns": [ 5598228594, 5600839598, 5600149767, 5598397171, 5598197071 ],"samples_ts": [ 182.915, 182.83, 182.852, 182.909, 182.916 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-04-15T10:44:53Z", "avg_ns": 21791571, "stddev_ns": 110242, "avg_ts": 734.243697, "stddev_ts": 3.683057, "samples_ns": [ 21988143, 21734130, 21746793, 21739753, 21749040 ],"samples_ts": [ 727.665, 736.169, 735.741, 735.979, 735.665 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-04-15T10:44:56Z", "avg_ns": 96218048, "stddev_ns": 170881, "avg_ts": 1330.315086, "stddev_ts": 2.354770, "samples_ns": [ 96503616, 96221383, 96189990, 96092629, 96082624 ],"samples_ts": [ 1326.38, 1330.27, 1330.7, 1332.05, 1332.19 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-04-15T10:44:59Z", "avg_ns": 179362498, "stddev_ns": 195149, "avg_ts": 2854.557047, "stddev_ts": 3.099067, "samples_ns": [ 179683843, 179272644, 179209562, 179239069, 179407373 ],"samples_ts": [ 2849.45, 2855.99, 2856.99, 2856.52, 2853.84 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-04-15T10:45:02Z", "avg_ns": 328303762, "stddev_ns": 206925, "avg_ts": 3119.063635, "stddev_ts": 1.965807, "samples_ns": [ 328412520, 328291418, 328195140, 328038372, 328581360 ],"samples_ts": [ 3118.03, 3119.18, 3120.09, 3121.59, 3116.43 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-04-15T10:45:06Z", "avg_ns": 1543818247, "stddev_ns": 1383674, "avg_ts": 2653.163762, "stddev_ts": 2.375771, "samples_ns": [ 1545884261, 1543245493, 1544542739, 1542898434, 1542520310 ],"samples_ts": [ 2649.62, 2654.15, 2651.92, 2654.74, 2655.39 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-04-15T10:45:18Z", "avg_ns": 11776623964, "stddev_ns": 3952720, "avg_ts": 1391.230757, "stddev_ts": 0.466827, "samples_ns": [ 11781436837, 11780174103, 11773986790, 11775056795, 11772465296 ],"samples_ts": [ 1390.66, 1390.81, 1391.54, 1391.42, 1391.72 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-04-15T10:46:32Z", "avg_ns": 135074523, "stddev_ns": 61708, "avg_ts": 118.453147, "stddev_ts": 0.052166, "samples_ns": [ 135133266, 135087203, 135126164, 135025265, 135000721 ],"samples_ts": [ 118.402, 118.442, 118.408, 118.496, 118.518 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-04-15T10:46:34Z", "avg_ns": 1125035496, "stddev_ns": 261075, "avg_ts": 113.774193, "stddev_ts": 0.026185, "samples_ns": [ 1125321177, 1125229539, 1124856234, 1125074477, 1124696055 ],"samples_ts": [ 113.745, 113.755, 113.792, 113.77, 113.809 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-04-15T10:46:42Z", "avg_ns": 4540152055, "stddev_ns": 917095, "avg_ts": 112.771557, "stddev_ts": 0.022716, "samples_ns": [ 4541036773, 4539626744, 4539494330, 4539349817, 4541252613 ],"samples_ts": [ 112.75, 112.785, 112.788, 112.791, 112.744 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-04-15T10:47:07Z", "avg_ns": 9294553507, "stddev_ns": 165685794, "avg_ts": 110.200494, "stddev_ts": 1.994740, "samples_ns": [ 9027850520, 9236051274, 9403586716, 9402069307, 9403209722 ],"samples_ts": [ 113.427, 110.87, 108.895, 108.912, 108.899 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-04-15T10:48:06Z", "avg_ns": 36342755, "stddev_ns": 114291, "avg_ts": 440.256250, "stddev_ts": 1.375316, "samples_ns": [ 36543652, 36312392, 36260649, 36294878, 36302208 ],"samples_ts": [ 437.833, 440.621, 441.25, 440.834, 440.745 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-04-15T10:48:10Z", "avg_ns": 203311201, "stddev_ns": 46949, "avg_ts": 629.576751, "stddev_ts": 0.145364, "samples_ns": [ 203340033, 203274045, 203284806, 203380066, 203277055 ],"samples_ts": [ 629.487, 629.692, 629.658, 629.364, 629.682 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-04-15T10:48:14Z", "avg_ns": 345214174, "stddev_ns": 486478, "avg_ts": 1483.139595, "stddev_ts": 2.088179, "samples_ns": [ 344489399, 345311518, 345790007, 345435160, 345044790 ],"samples_ts": [ 1486.26, 1482.72, 1480.67, 1482.19, 1483.87 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-04-15T10:48:20Z", "avg_ns": 640156679, "stddev_ns": 554859, "avg_ts": 1599.609355, "stddev_ts": 1.384850, "samples_ns": [ 640512831, 640522969, 640434038, 639215976, 640097585 ],"samples_ts": [ 1598.72, 1598.69, 1598.92, 1601.96, 1599.76 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-04-15T10:48:27Z", "avg_ns": 2833399188, "stddev_ns": 1414646, "avg_ts": 1445.613747, "stddev_ts": 0.722049, "samples_ns": [ 2831102570, 2833096827, 2834766265, 2834090412, 2833939866 ],"samples_ts": [ 1446.79, 1445.77, 1444.92, 1445.26, 1445.34 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-04-15T10:50:45Z", "avg_ns": 238308559, "stddev_ns": 82610, "avg_ts": 67.139853, "stddev_ts": 0.023272, "samples_ns": [ 238395095, 238400894, 238250921, 238265445, 238230440 ],"samples_ts": [ 67.1155, 67.1138, 67.1561, 67.152, 67.1619 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-04-15T10:50:50Z", "avg_ns": 1928514335, "stddev_ns": 8522485, "avg_ts": 66.373378, "stddev_ts": 0.295057, "samples_ns": [ 1913278338, 1932835831, 1932172181, 1932181702, 1932103625 ],"samples_ts": [ 66.9009, 66.2239, 66.2467, 66.2464, 66.249 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-04-15T10:51:03Z", "avg_ns": 7721366363, "stddev_ns": 133744287, "avg_ts": 66.325127, "stddev_ts": 1.127234, "samples_ns": [ 7641588070, 7641944184, 7643602785, 7728595243, 7951101533 ],"samples_ts": [ 67.0018, 66.9987, 66.9841, 66.2475, 64.3936 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-04-15T10:51:45Z", "avg_ns": 15801163300, "stddev_ns": 326664047, "avg_ts": 64.827662, "stddev_ts": 1.348795, "samples_ns": [ 15437329835, 15457928074, 15955192119, 16078376316, 16076990156 ],"samples_ts": [ 66.3327, 66.2443, 64.1797, 63.688, 63.6935 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-04-15T10:53:46Z", "avg_ns": 155483296, "stddev_ns": 134435, "avg_ts": 102.905006, "stddev_ts": 0.088885, "samples_ns": [ 155717646, 155437513, 155420590, 155461739, 155378992 ],"samples_ts": [ 102.75, 102.935, 102.946, 102.919, 102.974 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-04-15T10:53:57Z", "avg_ns": 813420854, "stddev_ns": 2297499, "avg_ts": 157.361116, "stddev_ts": 0.442763, "samples_ns": [ 817517612, 812542191, 812486338, 812470099, 812088033 ],"samples_ts": [ 156.572, 157.53, 157.541, 157.544, 157.618 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-04-15T10:54:12Z", "avg_ns": 1496146880, "stddev_ns": 2520468, "avg_ts": 342.213167, "stddev_ts": 0.576537, "samples_ns": [ 1492769313, 1499349732, 1496055083, 1494920377, 1497639896 ],"samples_ts": [ 342.987, 341.481, 342.233, 342.493, 341.871 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-04-15T10:54:31Z", "avg_ns": 2724419062, "stddev_ns": 2156615, "avg_ts": 375.860134, "stddev_ts": 0.297431, "samples_ns": [ 2722771425, 2726396856, 2725105314, 2726252686, 2721569033 ],"samples_ts": [ 376.087, 375.587, 375.765, 375.607, 376.254 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-04-15T10:54:58Z", "avg_ns": 11376735485, "stddev_ns": 7309494, "avg_ts": 360.033101, "stddev_ts": 0.231212, "samples_ns": [ 11378222241, 11368391196, 11375240958, 11373675507, 11388147525 ],"samples_ts": [ 359.986, 360.297, 360.08, 360.13, 359.672 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-04-15T10:56:17Z", "avg_ns": 933994896, "stddev_ns": 112817, "avg_ts": 17.130715, "stddev_ts": 0.002031, "samples_ns": [ 934063226, 933852522, 933996018, 934134904, 933927811 ],"samples_ts": [ 17.1295, 17.1333, 17.1307, 17.1281, 17.1319 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-04-15T10:56:32Z", "avg_ns": 7555471264, "stddev_ns": 100163080, "avg_ts": 16.943735, "stddev_ts": 0.223395, "samples_ns": [ 7482677854, 7483851382, 7482508708, 7644760493, 7683557883 ],"samples_ts": [ 17.1062, 17.1035, 17.1066, 16.7435, 16.6589 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-04-15T10:57:20Z", "avg_ns": 30712750472, "stddev_ns": 255787112, "avg_ts": 16.671536, "stddev_ts": 0.140416, "samples_ns": [ 30255187752, 30827408539, 30826708966, 30825975304, 30828471803 ],"samples_ts": [ 16.9227, 16.6086, 16.609, 16.6094, 16.608 ]}
