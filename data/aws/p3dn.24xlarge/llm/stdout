{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-04-18T13:48:38Z", "avg_ns": 9347057, "stddev_ns": 192067, "avg_ts": 1712.333766, "stddev_ts": 34.390865, "samples_ns": [ 9677729, 9351087, 9212634, 9246692, 9247147 ],"samples_ts": [ 1653.28, 1711.03, 1736.75, 1730.35, 1730.26 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-04-18T13:48:40Z", "avg_ns": 8576271, "stddev_ns": 88194, "avg_ts": 14926.145192, "stddev_ts": 151.427773, "samples_ns": [ 8731603, 8560717, 8519223, 8532170, 8537645 ],"samples_ts": [ 14659.4, 14952, 15024.8, 15002, 14992.4 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-04-18T13:48:43Z", "avg_ns": 14914035, "stddev_ns": 131978, "avg_ts": 34332.206935, "stddev_ts": 301.099312, "samples_ns": [ 15131683, 14945697, 14833220, 14814699, 14844880 ],"samples_ts": [ 33836.3, 34257.4, 34517.1, 34560.3, 34490 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-04-18T13:48:45Z", "avg_ns": 28678503, "stddev_ns": 52780, "avg_ts": 35706.281033, "stddev_ts": 65.002314, "samples_ns": [ 28658233, 28740854, 28727619, 28637640, 28628173 ],"samples_ts": [ 35731.4, 35628.7, 35645.1, 35757.1, 35769 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-04-18T13:48:48Z", "avg_ns": 139225174, "stddev_ns": 113523, "avg_ts": 29419.982470, "stddev_ts": 23.987538, "samples_ns": [ 139260390, 139383101, 139232828, 139074027, 139175524 ],"samples_ts": [ 29412.5, 29386.6, 29418.3, 29451.9, 29430.5 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-04-18T13:48:51Z", "avg_ns": 1046034167, "stddev_ns": 438004, "avg_ts": 15662.970462, "stddev_ts": 6.521903, "samples_ns": [ 1046629407, 1045562534, 1045716843, 1045953804, 1046308251 ],"samples_ts": [ 15654.1, 15670, 15667.7, 15664.2, 15658.9 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-04-18T13:49:00Z", "avg_ns": 61125398, "stddev_ns": 275802, "avg_ts": 261.761235, "stddev_ts": 1.177004, "samples_ns": [ 61571704, 61110164, 60877400, 60918568, 61149154 ],"samples_ts": [ 259.86, 261.822, 262.823, 262.646, 261.655 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-04-18T13:49:02Z", "avg_ns": 488105969, "stddev_ns": 1452598, "avg_ts": 262.239989, "stddev_ts": 0.777854, "samples_ns": [ 488119928, 490589558, 487100042, 487629843, 487090476 ],"samples_ts": [ 262.231, 260.911, 262.78, 262.494, 262.785 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-04-18T13:49:07Z", "avg_ns": 1999981767, "stddev_ns": 930933, "avg_ts": 256.002378, "stddev_ts": 0.118876, "samples_ns": [ 2001173806, 1999627882, 1998882314, 1999537345, 2000687492 ],"samples_ts": [ 255.85, 256.048, 256.143, 256.059, 255.912 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-04-18T13:49:19Z", "avg_ns": 4164875535, "stddev_ns": 11296777, "avg_ts": 245.867137, "stddev_ts": 0.666613, "samples_ns": [ 4179810859, 4172319075, 4162084467, 4159104547, 4151058727 ],"samples_ts": [ 244.987, 245.427, 246.031, 246.207, 246.684 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-04-18T13:49:46Z", "avg_ns": 7094607, "stddev_ns": 84055, "avg_ts": 2255.483444, "stddev_ts": 26.355288, "samples_ns": [ 7239334, 7077603, 7079861, 7051739, 7024502 ],"samples_ts": [ 2210.15, 2260.65, 2259.93, 2268.94, 2277.74 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-04-18T13:49:48Z", "avg_ns": 12650384, "stddev_ns": 45255, "avg_ts": 10118.372009, "stddev_ts": 36.003721, "samples_ns": [ 12712839, 12669837, 12654240, 12616018, 12598989 ],"samples_ts": [ 10068.6, 10102.7, 10115.2, 10145.8, 10159.5 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-04-18T13:49:51Z", "avg_ns": 24408176, "stddev_ns": 227820, "avg_ts": 20978.027160, "stddev_ts": 194.257967, "samples_ns": [ 24480510, 24305281, 24258706, 24221521, 24774865 ],"samples_ts": [ 20914.6, 21065.4, 21105.8, 21138.2, 20666.1 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-04-18T13:49:54Z", "avg_ns": 47007920, "stddev_ns": 232780, "avg_ts": 21783.987170, "stddev_ts": 107.140880, "samples_ns": [ 46892046, 47418195, 46961958, 46854204, 46913200 ],"samples_ts": [ 21837.4, 21595.1, 21804.9, 21855, 21827.5 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-04-18T13:49:57Z", "avg_ns": 221403570, "stddev_ns": 89110, "avg_ts": 18500.155659, "stddev_ts": 7.339182, "samples_ns": [ 221387174, 221422880, 221328087, 221544508, 221335203 ],"samples_ts": [ 18501.5, 18498.5, 18506.5, 18488.4, 18505.9 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-04-18T13:50:01Z", "avg_ns": 1580981382, "stddev_ns": 521291, "avg_ts": 10363.184285, "stddev_ts": 3.406206, "samples_ns": [ 1580692214, 1580562784, 1581192811, 1580657741, 1581801362 ],"samples_ts": [ 10365.1, 10365.9, 10361.8, 10365.3, 10357.8 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-04-18T13:50:13Z", "avg_ns": 64866286, "stddev_ns": 1642624, "avg_ts": 246.784181, "stddev_ts": 6.068136, "samples_ns": [ 64789145, 64021482, 63902999, 67728243, 63889565 ],"samples_ts": [ 246.955, 249.916, 250.379, 236.238, 250.432 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-04-18T13:50:16Z", "avg_ns": 511970486, "stddev_ns": 1038657, "avg_ts": 250.015233, "stddev_ts": 0.506459, "samples_ns": [ 513561358, 510803669, 512239563, 511393496, 511854348 ],"samples_ts": [ 249.24, 250.586, 249.883, 250.296, 250.071 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-04-18T13:50:21Z", "avg_ns": 2078915298, "stddev_ns": 2892848, "avg_ts": 246.282662, "stddev_ts": 0.342574, "samples_ns": [ 2081925952, 2077688761, 2082131649, 2076586259, 2076243869 ],"samples_ts": [ 245.926, 246.428, 245.902, 246.559, 246.599 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-04-18T13:50:33Z", "avg_ns": 4305259755, "stddev_ns": 1989351, "avg_ts": 237.848639, "stddev_ts": 0.109861, "samples_ns": [ 4307084585, 4305617532, 4307064727, 4304023111, 4302508822 ],"samples_ts": [ 237.748, 237.829, 237.749, 237.917, 238.001 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-04-18T13:51:03Z", "avg_ns": 10995602, "stddev_ns": 112062, "avg_ts": 1455.246582, "stddev_ts": 14.656738, "samples_ns": [ 11188331, 10994934, 10910498, 10936684, 10947566 ],"samples_ts": [ 1430.06, 1455.22, 1466.48, 1462.97, 1461.51 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-04-18T13:51:06Z", "avg_ns": 36546784, "stddev_ns": 66929, "avg_ts": 3502.369528, "stddev_ts": 6.399282, "samples_ns": [ 36664875, 36535609, 36509591, 36516030, 36507815 ],"samples_ts": [ 3491.08, 3503.43, 3505.93, 3505.31, 3506.1 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-04-18T13:51:09Z", "avg_ns": 71562005, "stddev_ns": 107511, "avg_ts": 7154.647510, "stddev_ts": 10.739831, "samples_ns": [ 71617451, 71636839, 71657614, 71486233, 71411889 ],"samples_ts": [ 7149.1, 7147.16, 7145.09, 7162.22, 7169.67 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-04-18T13:51:12Z", "avg_ns": 145468109, "stddev_ns": 174914, "avg_ts": 7039.351636, "stddev_ts": 8.429425, "samples_ns": [ 145713730, 145309953, 145397367, 145335209, 145584289 ],"samples_ts": [ 7027.48, 7047.01, 7042.77, 7045.78, 7033.73 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-04-18T13:51:16Z", "avg_ns": 722483046, "stddev_ns": 313892, "avg_ts": 5669.338044, "stddev_ts": 2.463865, "samples_ns": [ 721992527, 722359186, 722667354, 722774610, 722621553 ],"samples_ts": [ 5673.19, 5670.31, 5667.89, 5667.05, 5668.25 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-04-18T13:51:24Z", "avg_ns": 5327192558, "stddev_ns": 570871, "avg_ts": 3075.541192, "stddev_ts": 0.328220, "samples_ns": [ 5326664635, 5327872735, 5326891515, 5326792672, 5327741234 ],"samples_ts": [ 3075.85, 3075.15, 3075.71, 3075.77, 3075.22 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-04-18T13:51:59Z", "avg_ns": 91519867, "stddev_ns": 160402, "avg_ts": 174.825855, "stddev_ts": 0.305197, "samples_ns": [ 91802193, 91412546, 91460779, 91438309, 91485510 ],"samples_ts": [ 174.288, 175.031, 174.938, 174.981, 174.891 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-04-18T13:52:02Z", "avg_ns": 734486118, "stddev_ns": 292135, "avg_ts": 174.271525, "stddev_ts": 0.069025, "samples_ns": [ 734812239, 734431732, 734696291, 734059650, 734430680 ],"samples_ts": [ 174.194, 174.284, 174.222, 174.373, 174.285 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-04-18T13:52:09Z", "avg_ns": 2942125353, "stddev_ns": 1644687, "avg_ts": 174.023900, "stddev_ts": 0.097134, "samples_ns": [ 2944715190, 2942813078, 2940957191, 2940954792, 2941186518 ],"samples_ts": [ 173.871, 173.983, 174.093, 174.093, 174.079 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-04-18T13:52:26Z", "avg_ns": 5966775169, "stddev_ns": 2163531, "avg_ts": 171.617009, "stddev_ts": 0.062204, "samples_ns": [ 5969352958, 5968727178, 5966016153, 5964355594, 5965423963 ],"samples_ts": [ 171.543, 171.561, 171.639, 171.687, 171.656 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-04-18T13:53:06Z", "avg_ns": 23945429, "stddev_ns": 92532, "avg_ts": 668.193914, "stddev_ts": 2.569430, "samples_ns": [ 24104687, 23915786, 23936969, 23901411, 23868293 ],"samples_ts": [ 663.771, 669.014, 668.422, 669.417, 670.345 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-04-18T13:53:09Z", "avg_ns": 108797669, "stddev_ns": 73397, "avg_ts": 1176.496196, "stddev_ts": 0.777216, "samples_ns": [ 108910013, 108776520, 108777172, 108810752, 108713892 ],"samples_ts": [ 1175.28, 1176.72, 1176.72, 1176.35, 1177.4 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-04-18T13:53:14Z", "avg_ns": 200483949, "stddev_ns": 152501, "avg_ts": 2553.821587, "stddev_ts": 1.941183, "samples_ns": [ 200739371, 200502440, 200413699, 200411866, 200352369 ],"samples_ts": [ 2550.57, 2553.58, 2554.72, 2554.74, 2555.5 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-04-18T13:53:18Z", "avg_ns": 403082300, "stddev_ns": 119838, "avg_ts": 2540.424306, "stddev_ts": 0.755146, "samples_ns": [ 403154918, 402985595, 403004568, 403258895, 403007524 ],"samples_ts": [ 2539.97, 2541.03, 2540.91, 2539.31, 2540.9 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-04-18T13:53:24Z", "avg_ns": 1994989782, "stddev_ns": 355115, "avg_ts": 2053.143400, "stddev_ts": 0.365449, "samples_ns": [ 1994770007, 1994632789, 1995357037, 1995387675, 1994801402 ],"samples_ts": [ 2053.37, 2053.51, 2052.77, 2052.73, 2053.34 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2025-04-18T13:53:40Z", "avg_ns": 14203038045, "stddev_ns": 88374870, "avg_ts": 1153.591764, "stddev_ts": 7.181201, "samples_ns": [ 14287177557, 14108732990, 14211186313, 14116871166, 14291222199 ],"samples_ts": [ 1146.76, 1161.27, 1152.89, 1160.6, 1146.44 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-04-18T13:55:09Z", "avg_ns": 143057146, "stddev_ns": 62198, "avg_ts": 111.843432, "stddev_ts": 0.047261, "samples_ns": [ 143135781, 143064085, 143085137, 142976354, 143024376 ],"samples_ts": [ 111.782, 111.838, 111.822, 111.907, 111.869 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-04-18T13:55:13Z", "avg_ns": 1162611878, "stddev_ns": 353121, "avg_ts": 110.096939, "stddev_ts": 0.033433, "samples_ns": [ 1162546784, 1163172490, 1162257339, 1162690757, 1162392020 ],"samples_ts": [ 110.103, 110.044, 110.131, 110.089, 110.118 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-04-18T13:55:22Z", "avg_ns": 4753128236, "stddev_ns": 90480141, "avg_ts": 107.749072, "stddev_ts": 2.005418, "samples_ns": [ 4692140756, 4699860395, 4722620169, 4739542764, 4911477098 ],"samples_ts": [ 109.119, 108.939, 108.414, 108.027, 104.246 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-04-18T13:55:49Z", "avg_ns": 10046026187, "stddev_ns": 3251420, "avg_ts": 101.930860, "stddev_ts": 0.032992, "samples_ns": [ 10049051266, 10049176676, 10046609759, 10042762192, 10042531042 ],"samples_ts": [ 101.9, 101.899, 101.925, 101.964, 101.966 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-04-18T13:56:54Z", "avg_ns": 42115190, "stddev_ns": 95345, "avg_ts": 379.911988, "stddev_ts": 0.859615, "samples_ns": [ 42236934, 42190489, 42019929, 42092736, 42035862 ],"samples_ts": [ 378.815, 379.232, 380.772, 380.113, 380.627 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-04-18T13:56:59Z", "avg_ns": 229461697, "stddev_ns": 229259, "avg_ts": 557.827750, "stddev_ts": 0.557116, "samples_ns": [ 229811338, 229488079, 229385090, 229176709, 229447269 ],"samples_ts": [ 556.979, 557.763, 558.014, 558.521, 557.862 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-04-18T13:57:06Z", "avg_ns": 389893593, "stddev_ns": 320265, "avg_ts": 1313.179505, "stddev_ts": 1.077030, "samples_ns": [ 389956855, 390401071, 389619686, 389865352, 389625002 ],"samples_ts": [ 1312.97, 1311.47, 1314.1, 1313.27, 1314.08 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-04-18T13:57:13Z", "avg_ns": 770008711, "stddev_ns": 216253, "avg_ts": 1329.855168, "stddev_ts": 0.372012, "samples_ns": [ 769682528, 769893226, 770172518, 770160937, 770134347 ],"samples_ts": [ 1330.42, 1330.05, 1329.57, 1329.59, 1329.64 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-04-18T13:57:22Z", "avg_ns": 3420524439, "stddev_ns": 34776355, "avg_ts": 1197.575475, "stddev_ts": 12.083915, "samples_ns": [ 3475532658, 3433352261, 3406590262, 3393926220, 3393220795 ],"samples_ts": [ 1178.52, 1193, 1202.38, 1206.86, 1207.11 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-04-18T13:59:46Z", "avg_ns": 259696403, "stddev_ns": 1406092, "avg_ts": 61.611842, "stddev_ts": 0.332315, "samples_ns": [ 258786744, 258695343, 258733972, 260417630, 261848329 ],"samples_ts": [ 61.827, 61.8488, 61.8396, 61.4398, 61.1041 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-04-18T13:59:52Z", "avg_ns": 2086754454, "stddev_ns": 546566, "avg_ts": 61.339276, "stddev_ts": 0.016038, "samples_ns": [ 2087379675, 2087192534, 2086221305, 2086186746, 2086792011 ],"samples_ts": [ 61.3209, 61.3264, 61.3549, 61.356, 61.3382 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-04-18T14:00:07Z", "avg_ns": 8409926176, "stddev_ns": 26993417, "avg_ts": 60.880941, "stddev_ts": 0.195378, "samples_ns": [ 8378276087, 8391108193, 8404998753, 8437836018, 8437411831 ],"samples_ts": [ 61.1104, 61.017, 60.9161, 60.6791, 60.6821 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2025-04-18T14:00:53Z", "avg_ns": 17036264630, "stddev_ns": 28496716, "avg_ts": 60.107208, "stddev_ts": 0.100697, "samples_ns": [ 16989182323, 17029937274, 17055887698, 17057377320, 17048938536 ],"samples_ts": [ 60.2736, 60.1294, 60.0379, 60.0327, 60.0624 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2025-04-18T14:03:11Z", "avg_ns": 161445455, "stddev_ns": 325054, "avg_ts": 99.104998, "stddev_ts": 0.198782, "samples_ns": [ 161407578, 161223309, 161366353, 162006686, 161223353 ],"samples_ts": [ 99.1279, 99.2412, 99.1533, 98.7614, 99.2412 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2025-04-18T14:03:27Z", "avg_ns": 883124589, "stddev_ns": 12708693, "avg_ts": 144.963476, "stddev_ts": 2.046817, "samples_ns": [ 905833302, 878105547, 876943845, 877976794, 876763458 ],"samples_ts": [ 141.306, 145.768, 145.961, 145.79, 145.991 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2025-04-18T14:03:47Z", "avg_ns": 1591278654, "stddev_ns": 1920323, "avg_ts": 321.754203, "stddev_ts": 0.387980, "samples_ns": [ 1594065445, 1590822608, 1588916002, 1592063056, 1590526163 ],"samples_ts": [ 321.191, 321.846, 322.232, 321.595, 321.906 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2025-04-18T14:04:12Z", "avg_ns": 3045734305, "stddev_ns": 4951145, "avg_ts": 336.208632, "stddev_ts": 0.546877, "samples_ns": [ 3044200396, 3038268643, 3051335187, 3048616148, 3046251155 ],"samples_ts": [ 336.377, 337.034, 335.591, 335.89, 336.151 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2025-04-18T14:04:45Z", "avg_ns": 13403186565, "stddev_ns": 4996369, "avg_ts": 305.599003, "stddev_ts": 0.113866, "samples_ns": [ 13396246906, 13401102840, 13406589569, 13409148903, 13402844611 ],"samples_ts": [ 305.757, 305.646, 305.521, 305.463, 305.607 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2025-04-18T14:06:21Z", "avg_ns": 1023268897, "stddev_ns": 365952, "avg_ts": 15.636165, "stddev_ts": 0.005593, "samples_ns": [ 1023042570, 1023361650, 1023612664, 1022754172, 1023573429 ],"samples_ts": [ 15.6396, 15.6347, 15.6309, 15.644, 15.6315 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2025-04-18T14:06:41Z", "avg_ns": 8114437408, "stddev_ns": 84773920, "avg_ts": 15.775737, "stddev_ts": 0.165562, "samples_ns": [ 8003860416, 8041630893, 8177918548, 8174046640, 8174730545 ],"samples_ts": [ 15.9923, 15.9172, 15.6519, 15.6593, 15.658 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz", "gpu_info": "Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB, Tesla V100-SXM2-32GB", "backends": "CUDA", "model_filename": "/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf", "model_type": "llama 70B Q4_K - Medium", "model_size": 42512531712, "model_n_params": 70553706560, "n_batch": 2048, "n_ubatch": 512, "n_threads": 48, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2025-04-18T14:07:36Z", "avg_ns": 32857984532, "stddev_ns": 53846211, "avg_ts": 15.582243, "stddev_ts": 0.025591, "samples_ns": [ 32761769356, 32885401271, 32881519045, 32882860666, 32878372326 ],"samples_ts": [ 15.628, 15.5692, 15.5711, 15.5704, 15.5725 ]}
