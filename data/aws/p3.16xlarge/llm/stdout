{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2026-01-30T10:35:37Z", "avg_ns": 9396916, "stddev_ns": 222119, "avg_ts": 1703.424632, "stddev_ts": 39.057344, "samples_ns": [ 9791933, 9329575, 9309553, 9287036, 9266486 ],"samples_ts": [ 1634, 1714.98, 1718.66, 1722.83, 1726.65 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2026-01-30T10:35:41Z", "avg_ns": 8796541, "stddev_ns": 126814, "avg_ts": 14553.550466, "stddev_ts": 206.160513, "samples_ns": [ 9019125, 8761561, 8700253, 8757402, 8744366 ],"samples_ts": [ 14192.1, 14609.3, 14712.2, 14616.2, 14638 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2026-01-30T10:35:45Z", "avg_ns": 14951674, "stddev_ns": 152139, "avg_ts": 34246.499700, "stddev_ts": 349.304494, "samples_ns": [ 15126349, 15062071, 14888788, 14943583, 14737580 ],"samples_ts": [ 33848.2, 33992.7, 34388.3, 34262.2, 34741.1 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2026-01-30T10:35:49Z", "avg_ns": 28509155, "stddev_ns": 94920, "avg_ts": 35918.603271, "stddev_ts": 119.267705, "samples_ns": [ 28517566, 28507653, 28479463, 28652289, 28388806 ],"samples_ts": [ 35907.7, 35920.2, 35955.7, 35738.9, 36070.6 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2026-01-30T10:35:53Z", "avg_ns": 139101980, "stddev_ns": 256582, "avg_ts": 29446.101921, "stddev_ts": 54.153035, "samples_ns": [ 138855886, 138994439, 138973434, 139512781, 139173363 ],"samples_ts": [ 29498.2, 29468.8, 29473.3, 29359.3, 29430.9 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2026-01-30T10:35:58Z", "avg_ns": 1052187547, "stddev_ns": 2905807, "avg_ts": 15571.463524, "stddev_ts": 43.023852, "samples_ns": [ 1052474809, 1055929120, 1048058275, 1053385580, 1051089952 ],"samples_ts": [ 15567.1, 15516.2, 15632.7, 15553.7, 15587.6 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2026-01-30T10:36:08Z", "avg_ns": 64129948, "stddev_ns": 709302, "avg_ts": 249.517714, "stddev_ts": 2.746268, "samples_ns": [ 65156924, 64517497, 63932388, 63403880, 63639054 ],"samples_ts": [ 245.561, 247.995, 250.264, 252.35, 251.418 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2026-01-30T10:36:13Z", "avg_ns": 505989003, "stddev_ns": 3300361, "avg_ts": 252.978515, "stddev_ts": 1.646321, "samples_ns": [ 509388155, 503172656, 509787358, 503969751, 503627095 ],"samples_ts": [ 251.282, 254.386, 251.085, 253.983, 254.156 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2026-01-30T10:36:19Z", "avg_ns": 2047545690, "stddev_ns": 3158642, "avg_ts": 250.055946, "stddev_ts": 0.385426, "samples_ns": [ 2052183699, 2049364145, 2045216132, 2046239751, 2044724723 ],"samples_ts": [ 249.49, 249.834, 250.34, 250.215, 250.4 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/SmolLM-135M.Q4_K_M.gguf", "model_type": "llama ?B Q4_K - Medium", "model_size": 103668480, "model_n_params": 134515008, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2026-01-30T10:36:32Z", "avg_ns": 4269650319, "stddev_ns": 4597592, "avg_ts": 239.832509, "stddev_ts": 0.258143, "samples_ns": [ 4275924096, 4268881827, 4264501114, 4266472511, 4272472050 ],"samples_ts": [ 239.48, 239.875, 240.122, 240.011, 239.674 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2026-01-30T10:37:03Z", "avg_ns": 7092772, "stddev_ns": 132847, "avg_ts": 2256.437171, "stddev_ts": 41.349526, "samples_ns": [ 7324825, 7072920, 6992259, 7039341, 7034515 ],"samples_ts": [ 2184.35, 2262.15, 2288.24, 2272.94, 2274.5 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2026-01-30T10:37:06Z", "avg_ns": 12535815, "stddev_ns": 122894, "avg_ts": 10211.520336, "stddev_ts": 99.008006, "samples_ns": [ 12748317, 12478336, 12513507, 12505665, 12433251 ],"samples_ts": [ 10040.5, 10257.8, 10228.9, 10235.4, 10295 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2026-01-30T10:37:11Z", "avg_ns": 24254399, "stddev_ns": 152435, "avg_ts": 21110.235792, "stddev_ts": 132.015251, "samples_ns": [ 24502005, 24247971, 24225136, 24084455, 24212430 ],"samples_ts": [ 20896.2, 21115.2, 21135.1, 21258.5, 21146.2 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2026-01-30T10:37:15Z", "avg_ns": 46635038, "stddev_ns": 108253, "avg_ts": 21957.833748, "stddev_ts": 51.037940, "samples_ns": [ 46452240, 46686272, 46630776, 46675571, 46730332 ],"samples_ts": [ 22044.1, 21933.6, 21959.7, 21938.7, 21913 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2026-01-30T10:37:19Z", "avg_ns": 219325801, "stddev_ns": 73705, "avg_ts": 18675.414869, "stddev_ts": 6.016792, "samples_ns": [ 219247495, 219271734, 219324748, 219360754, 219424278 ],"samples_ts": [ 18682.1, 18680, 18675.5, 18672.4, 18667 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2026-01-30T10:37:25Z", "avg_ns": 1563689203, "stddev_ns": 692267, "avg_ts": 10477.787094, "stddev_ts": 4.626827, "samples_ns": [ 1564701562, 1563859531, 1562788189, 1563581348, 1563515388 ],"samples_ts": [ 10471, 10476.6, 10483.8, 10478.5, 10479 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2026-01-30T10:37:39Z", "avg_ns": 65077925, "stddev_ns": 204168, "avg_ts": 245.861023, "stddev_ts": 0.767802, "samples_ns": [ 65436095, 64932452, 65040669, 64978965, 65001446 ],"samples_ts": [ 244.513, 246.41, 246, 246.234, 246.148 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2026-01-30T10:37:43Z", "avg_ns": 530566370, "stddev_ns": 418619, "avg_ts": 241.251747, "stddev_ts": 0.190018, "samples_ns": [ 530189323, 530383239, 531002013, 530225149, 531032128 ],"samples_ts": [ 241.423, 241.335, 241.054, 241.407, 241.04 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2026-01-30T10:37:50Z", "avg_ns": 2111492108, "stddev_ns": 4066952, "avg_ts": 242.483273, "stddev_ts": 0.466554, "samples_ns": [ 2114234264, 2117265050, 2109402847, 2108660502, 2107897880 ],"samples_ts": [ 242.168, 241.821, 242.723, 242.808, 242.896 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/qwen1_5-0_5b-chat-q4_k_m.gguf", "model_type": "qwen2 0.5B Q4_K - Medium", "model_size": 401210368, "model_n_params": 619570176, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2026-01-30T10:38:04Z", "avg_ns": 4374642903, "stddev_ns": 11436569, "avg_ts": 234.077527, "stddev_ts": 0.611354, "samples_ns": [ 4387568394, 4386751759, 4366120257, 4366895312, 4365878795 ],"samples_ts": [ 233.387, 233.43, 234.533, 234.492, 234.546 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2026-01-30T10:38:36Z", "avg_ns": 10760815, "stddev_ns": 111967, "avg_ts": 1487.003126, "stddev_ts": 15.264744, "samples_ns": [ 10958202, 10727019, 10683326, 10706204, 10729327 ],"samples_ts": [ 1460.09, 1491.56, 1497.66, 1494.46, 1491.24 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2026-01-30T10:38:41Z", "avg_ns": 35364744, "stddev_ns": 104329, "avg_ts": 3619.448961, "stddev_ts": 10.631813, "samples_ns": [ 35546841, 35350687, 35318103, 35320875, 35287215 ],"samples_ts": [ 3600.88, 3620.86, 3624.2, 3623.92, 3627.38 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2026-01-30T10:38:45Z", "avg_ns": 69591474, "stddev_ns": 289446, "avg_ts": 7357.324407, "stddev_ts": 30.459460, "samples_ns": [ 70086713, 69581317, 69507660, 69423092, 69358589 ],"samples_ts": [ 7305.24, 7358.3, 7366.09, 7375.07, 7381.93 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2026-01-30T10:38:50Z", "avg_ns": 141687565, "stddev_ns": 233610, "avg_ts": 7227.184842, "stddev_ts": 11.905386, "samples_ns": [ 141918254, 141423391, 141611017, 141946412, 141538752 ],"samples_ts": [ 7215.42, 7240.67, 7231.08, 7213.99, 7234.77 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2026-01-30T10:38:56Z", "avg_ns": 703960363, "stddev_ns": 488917, "avg_ts": 5818.511646, "stddev_ts": 4.033797, "samples_ns": [ 703207974, 703789906, 704224727, 704102386, 704476825 ],"samples_ts": [ 5824.73, 5819.92, 5816.33, 5817.34, 5814.24 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2026-01-30T10:39:05Z", "avg_ns": 5164345618, "stddev_ns": 951242, "avg_ts": 3172.522068, "stddev_ts": 0.582639, "samples_ns": [ 5164796832, 5164154683, 5165745554, 5163617417, 5163413606 ],"samples_ts": [ 3172.24, 3172.64, 3171.66, 3172.97, 3173.09 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2026-01-30T10:39:40Z", "avg_ns": 92755004, "stddev_ns": 380080, "avg_ts": 172.499737, "stddev_ts": 0.703594, "samples_ns": [ 93402893, 92752962, 92481488, 92651253, 92486426 ],"samples_ts": [ 171.301, 172.501, 173.008, 172.691, 172.998 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2026-01-30T10:39:45Z", "avg_ns": 718389500, "stddev_ns": 1125195, "avg_ts": 178.176672, "stddev_ts": 0.278495, "samples_ns": [ 718388798, 717985149, 720309631, 717456148, 717807777 ],"samples_ts": [ 178.176, 178.277, 177.701, 178.408, 178.321 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2026-01-30T10:39:53Z", "avg_ns": 2979763966, "stddev_ns": 2162391, "avg_ts": 171.825762, "stddev_ts": 0.124603, "samples_ns": [ 2981104813, 2977523772, 2982758223, 2979312182, 2978120843 ],"samples_ts": [ 171.748, 171.955, 171.653, 171.852, 171.92 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/gemma-2b.Q4_K_M.gguf", "model_type": "gemma 2B Q4_K - Medium", "model_size": 1489055744, "model_n_params": 2506172416, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2026-01-30T10:40:12Z", "avg_ns": 5846904904, "stddev_ns": 1411933, "avg_ts": 175.135403, "stddev_ts": 0.042296, "samples_ns": [ 5848055604, 5845629363, 5845118152, 5847902750, 5847818651 ],"samples_ts": [ 175.101, 175.174, 175.189, 175.106, 175.108 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2026-01-30T10:40:53Z", "avg_ns": 23420669, "stddev_ns": 91056, "avg_ts": 683.165475, "stddev_ts": 2.645847, "samples_ns": [ 23568969, 23350631, 23409507, 23430963, 23343276 ],"samples_ts": [ 678.859, 685.206, 683.483, 682.857, 685.422 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2026-01-30T10:40:58Z", "avg_ns": 104535614, "stddev_ns": 210703, "avg_ts": 1224.467044, "stddev_ts": 2.460439, "samples_ns": [ 104906726, 104473065, 104484390, 104405639, 104408251 ],"samples_ts": [ 1220.13, 1225.2, 1225.06, 1225.99, 1225.96 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2026-01-30T10:41:04Z", "avg_ns": 194664195, "stddev_ns": 398691, "avg_ts": 2630.179173, "stddev_ts": 5.372075, "samples_ns": [ 195341633, 194477148, 194691481, 194461900, 194348815 ],"samples_ts": [ 2621.05, 2632.7, 2629.8, 2632.91, 2634.44 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2026-01-30T10:41:09Z", "avg_ns": 389962102, "stddev_ns": 239888, "avg_ts": 2625.896982, "stddev_ts": 1.609479, "samples_ns": [ 389894035, 389682595, 389854137, 390313268, 390066477 ],"samples_ts": [ 2626.35, 2627.78, 2626.62, 2623.53, 2625.19 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2026-01-30T10:41:17Z", "avg_ns": 1921879669, "stddev_ns": 296637, "avg_ts": 2131.246895, "stddev_ts": 0.328935, "samples_ns": [ 1921826743, 1921548191, 1922305551, 1922027839, 1921690021 ],"samples_ts": [ 2131.31, 2131.61, 2130.77, 2131.08, 2131.46 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16384, "n_gen": 0, "test_time": "2026-01-30T10:41:33Z", "avg_ns": 13666382213, "stddev_ns": 82584633, "avg_ts": 1198.889320, "stddev_ts": 7.260506, "samples_ns": [ 13720913558, 13575229190, 13732505955, 13576828740, 13726433622 ],"samples_ts": [ 1194.09, 1206.9, 1193.08, 1206.76, 1193.61 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2026-01-30T10:43:01Z", "avg_ns": 141143325, "stddev_ns": 592313, "avg_ts": 113.361546, "stddev_ts": 0.476247, "samples_ns": [ 141658758, 141586822, 140512365, 141473427, 140485256 ],"samples_ts": [ 112.947, 113.005, 113.869, 113.095, 113.891 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2026-01-30T10:43:06Z", "avg_ns": 1153996610, "stddev_ns": 467635, "avg_ts": 110.918885, "stddev_ts": 0.044943, "samples_ns": [ 1153389262, 1153905609, 1154069465, 1153924227, 1154694487 ],"samples_ts": [ 110.977, 110.928, 110.912, 110.926, 110.852 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2026-01-30T10:43:16Z", "avg_ns": 4716579058, "stddev_ns": 45591159, "avg_ts": 108.561338, "stddev_ts": 1.045476, "samples_ns": [ 4685946472, 4683098746, 4681318314, 4760181134, 4772350624 ],"samples_ts": [ 109.263, 109.329, 109.371, 107.559, 107.285 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/llama-7b.Q4_K_M.gguf", "model_type": "llama 7B Q4_K - Medium", "model_size": 4080263168, "model_n_params": 6738415616, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2026-01-30T10:43:44Z", "avg_ns": 9747631261, "stddev_ns": 4027834, "avg_ts": 105.051177, "stddev_ts": 0.043392, "samples_ns": [ 9753947662, 9747987258, 9746871976, 9746517487, 9742831923 ],"samples_ts": [ 104.983, 105.047, 105.059, 105.063, 105.103 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 16, "n_gen": 0, "test_time": "2026-01-30T10:44:50Z", "avg_ns": 38741337, "stddev_ns": 113294, "avg_ts": 412.998352, "stddev_ts": 1.202369, "samples_ns": [ 38904740, 38809839, 38632315, 38690011, 38669784 ],"samples_ts": [ 411.261, 412.267, 414.161, 413.543, 413.76 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 128, "n_gen": 0, "test_time": "2026-01-30T10:44:56Z", "avg_ns": 210636805, "stddev_ns": 112201, "avg_ts": 607.681209, "stddev_ts": 0.320987, "samples_ns": [ 210762873, 210494529, 210575572, 210617947, 210733106 ],"samples_ts": [ 607.318, 608.092, 607.858, 607.735, 607.403 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 512, "n_gen": 0, "test_time": "2026-01-30T10:45:03Z", "avg_ns": 350892205, "stddev_ns": 491810, "avg_ts": 1459.139861, "stddev_ts": 2.044319, "samples_ns": [ 351199374, 350745774, 351487035, 350839268, 350189576 ],"samples_ts": [ 1457.86, 1459.75, 1456.67, 1459.36, 1462.07 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 1024, "n_gen": 0, "test_time": "2026-01-30T10:45:11Z", "avg_ns": 693178018, "stddev_ns": 201345, "avg_ts": 1477.254099, "stddev_ts": 0.427292, "samples_ns": [ 692966438, 693272330, 693364496, 693330421, 692956406 ],"samples_ts": [ 1477.71, 1477.05, 1476.86, 1476.93, 1477.73 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 4096, "n_gen": 0, "test_time": "2026-01-30T10:45:21Z", "avg_ns": 3273549600, "stddev_ns": 14586941, "avg_ts": 1251.261037, "stddev_ts": 5.575873, "samples_ns": [ 3255856132, 3291291079, 3283856002, 3274004805, 3262739985 ],"samples_ts": [ 1258.04, 1244.5, 1247.31, 1251.07, 1255.39 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 16, "test_time": "2026-01-30T10:47:45Z", "avg_ns": 247225554, "stddev_ns": 232777, "avg_ts": 64.718274, "stddev_ts": 0.060608, "samples_ns": [ 247161554, 246988438, 247219063, 247147962, 247610757 ],"samples_ts": [ 64.735, 64.7804, 64.7199, 64.7385, 64.6175 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 128, "test_time": "2026-01-30T10:47:52Z", "avg_ns": 1961950554, "stddev_ns": 1387582, "avg_ts": 65.241222, "stddev_ts": 0.046103, "samples_ns": [ 1960411638, 1961928122, 1963695031, 1960795733, 1962922249 ],"samples_ts": [ 65.2924, 65.2419, 65.1832, 65.2796, 65.2089 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 512, "test_time": "2026-01-30T10:48:07Z", "avg_ns": 7978006704, "stddev_ns": 168449392, "avg_ts": 64.199233, "stddev_ts": 1.349913, "samples_ns": [ 7825537954, 7821448783, 7930784015, 8150800415, 8161462357 ],"samples_ts": [ 65.4268, 65.461, 64.5586, 62.8159, 62.7339 ]}
{"build_commit": "51f311e0", "build_number": 4753, "cpu_info": "Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz", "gpu_info": "Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB, Tesla V100-SXM2-16GB", "backends": "CUDA", "model_filename": "/models/phi-4-q4.gguf", "model_type": "phi3 14B Q4_K - Medium", "model_size": 9049559040, "model_n_params": 14659507200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 32, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 999, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "use_mmap": true, "embeddings": false, "n_prompt": 0, "n_gen": 1024, "test_time": "2026-01-30T10:48:53Z", "avg_ns": 16414417519, "stddev_ns": 93097572, "avg_ts": 62.385788, "stddev_ts": 0.354149, "samples_ns": [ 16296771326, 16345710616, 16422281345, 16496038146, 16511286164 ],"samples_ts": [ 62.8345, 62.6464, 62.3543, 62.0755, 62.0182 ]}
